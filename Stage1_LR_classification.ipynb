{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b1d4fb",
   "metadata": {},
   "source": [
    "# Stage 1 - Classification of Images from Left/Right Quadrants\n",
    "\n",
    "This notebook is at Stage 1 of the tooth detection and numbering pipeline. It is going to train a CNN based on ResNet50 which can classify images taken at the left quadrant or right quadrant. This work is implemented according to https://github.com/bentrevett/pytorch-image-classification/blob/master/5_resnet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f93551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98589706",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 721\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ee625",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage1_dataset_LR_classifier'\n",
    "train_dir = os.path.join(images_dir, 'train')\n",
    "test_dir = os.path.join(images_dir, 'test')\n",
    "test_pred_output_dir = os.path.join(images_dir, 'test_preds')\n",
    "\n",
    "classes = ['LEFT', 'RIGHT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, cast, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "class ToothImageFolder(datasets.ImageFolder):\n",
    "    \n",
    "    def __init__(self, root: str, transform: Optional[Callable] = None):\n",
    "        \n",
    "        super().__init__(root, transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = super().__getitem__(index)\n",
    "        fname = self.samples[index]\n",
    "\n",
    "        return img, label, fname[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db024a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ToothImageFolder(root = train_dir, \n",
    "                                  transform = transforms.ToTensor())\n",
    "\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "\n",
    "for img, label, _ in train_data:\n",
    "    means += torch.mean(img, dim = (1,2))\n",
    "    stds += torch.std(img, dim = (1,2))\n",
    "\n",
    "means /= len(train_data)\n",
    "stds /= len(train_data)\n",
    "    \n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the means and stds are copied from the calculations in the input dataset above\n",
    "\n",
    "pretrained_size = 224\n",
    "pretrained_means = means.tolist()\n",
    "pretrained_stds = stds.tolist()\n",
    "\n",
    "# Don't need transforms.RandomHorizontalFlip(0.5), as we train it for left/right classification\n",
    "#transforms.RandomCrop(pretrained_size, padding = 10),\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           # transforms.RandomHorizontalFlip(0.5),\n",
    "                           # transforms.RandomRotation(5),\n",
    "                           transforms.RandomRotation(90),\n",
    "                           transforms.RandomCrop(pretrained_size, padding = 10),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.CenterCrop(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ToothImageFolder(root = train_dir, \n",
    "                                  transform = train_transforms)\n",
    "\n",
    "test_data = ToothImageFolder(root = test_dir, \n",
    "                                 transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d491599",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data, \n",
    "                                           [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90bd42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2644c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "train_iterator = data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ed35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels, classes, normalize = True):\n",
    "\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        \n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        label = classes[labels[i]]\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffaf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 25\n",
    "\n",
    "images, labels = zip(*[(image, label) for image, label, _ in \n",
    "                           [train_data[i] for i in range(N_IMAGES)]])\n",
    "\n",
    "classes = test_data.classes\n",
    "\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49564fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = models.resnet50(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, config, output_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        block, n_blocks, channels = config\n",
    "        self.in_channels = channels[0]\n",
    "            \n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "        \n",
    "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "        \n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        \n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "        \n",
    "        return x, h\n",
    "\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "                        \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                               stride = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
    "                               stride = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "            \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "                \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "            \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = pretrained_model.fc.in_features \n",
    "OUTPUT_DIM = len(test_data.classes)\n",
    "\n",
    "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.fc = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e53f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])\n",
    "resnet50_config = ResNetConfig(block = Bottleneck,\n",
    "                               n_blocks = [3, 4, 6, 3],\n",
    "                               channels = [64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(resnet50_config, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d23ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(pretrained_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_LR = 1e-7\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRFinder:\n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        \n",
    "        torch.save(model.state_dict(), 'init_params.pt')\n",
    "\n",
    "    def range_test(self, iterator, end_lr = 10, num_iter = 100, \n",
    "                   smooth_f = 0.05, diverge_th = 5):\n",
    "        \n",
    "        lrs = []\n",
    "        losses = []\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
    "        \n",
    "        iterator = IteratorWrapper(iterator)\n",
    "        \n",
    "        for iteration in range(num_iter):\n",
    "\n",
    "            loss = self._train_batch(iterator)\n",
    "\n",
    "            #update lr\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            lrs.append(lr_scheduler.get_lr()[0])\n",
    "\n",
    "            if iteration > 0:\n",
    "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
    "                \n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "\n",
    "            losses.append(loss)\n",
    "            \n",
    "            if loss > diverge_th * best_loss:\n",
    "                print(\"Stopping early, the loss has diverged\")\n",
    "                break\n",
    "                       \n",
    "        #reset model to initial parameters\n",
    "        model.load_state_dict(torch.load('init_params.pt'))\n",
    "                    \n",
    "        return lrs, losses\n",
    "\n",
    "    def _train_batch(self, iterator):\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        x, y = iterator.get_batch()\n",
    "        \n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        \n",
    "        y_pred, _ = self.model(x)\n",
    "                \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "class ExponentialLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
    "        self.end_lr = end_lr\n",
    "        self.num_iter = num_iter\n",
    "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        curr_iter = self.last_epoch + 1\n",
    "        r = curr_iter / self.num_iter\n",
    "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
    "\n",
    "class IteratorWrapper:\n",
    "    def __init__(self, iterator):\n",
    "        self.iterator = iterator\n",
    "        self._iterator = iter(iterator)\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            inputs, labels, _ = next(self._iterator)\n",
    "        except StopIteration:\n",
    "            self._iterator = iter(self.iterator)\n",
    "            inputs, labels, *_ = next(self._iterator)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def get_batch(self):\n",
    "        return next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72562629",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_LR = 10\n",
    "NUM_ITER = 100\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device)\n",
    "lrs, losses = lr_finder.range_test(train_iterator, END_LR, NUM_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c3f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_finder(lrs, losses, skip_start = 5, skip_end = 5):\n",
    "    \n",
    "    if skip_end == 0:\n",
    "        lrs = lrs[skip_start:]\n",
    "        losses = losses[skip_start:]\n",
    "    else:\n",
    "        lrs = lrs[skip_start:-skip_end]\n",
    "        losses = losses[skip_start:-skip_end]\n",
    "    \n",
    "    fig = plt.figure(figsize = (16,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(lrs, losses)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Learning rate')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.grid(True, 'both', 'x')\n",
    "    plt.show()\n",
    "    \n",
    "plot_lr_finder(lrs, losses, skip_start = 30, skip_end = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca753e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOUND_LR = 1e-3\n",
    "\n",
    "params = [\n",
    "          {'params': model.conv1.parameters(), 'lr': FOUND_LR / 10},\n",
    "          {'params': model.bn1.parameters(), 'lr': FOUND_LR / 10},\n",
    "          {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
    "          {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
    "          {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
    "          {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
    "          {'params': model.fc.parameters()}\n",
    "         ]\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(params, lr = FOUND_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 35\n",
    "STEPS_PER_EPOCH = len(train_iterator)\n",
    "TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
    "\n",
    "MAX_LRS = [p['lr'] for p in optimizer.param_groups]\n",
    "\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer,\n",
    "                                    max_lr = MAX_LRS,\n",
    "                                    total_steps = TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f702277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topk_accuracy(y_pred, y, k = 1):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(k, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
    "        acc_1 = correct_1 / batch_size\n",
    "        acc_k = correct_k / batch_size\n",
    "    return acc_1, acc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, scheduler, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    #epoch_acc_5 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y, fname) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred, _ = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        #acc_1,acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "        acc_1, _ = calculate_topk_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        #epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    #epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    #return epoch_loss, epoch_acc_1, epoch_acc_5\n",
    "    return epoch_loss, epoch_acc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    #epoch_acc_5 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y, fname) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            #acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "            acc_1, _ = calculate_topk_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc_1 += acc_1.item()\n",
    "            #epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    #epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "#     return epoch_loss, epoch_acc_1, epoch_acc_5\n",
    "    return epoch_loss, epoch_acc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fcfb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_loss_lst = [] \n",
    "valid_loss_lst = []\n",
    "train_acc_lst = []\n",
    "valid_acc_lst = []\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "#     train_loss, train_acc_1, train_acc_5 = train(model, train_iterator, optimizer, criterion, scheduler, device)\n",
    "#     valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    train_loss, train_acc_1 = train(model, train_iterator, optimizer, criterion, scheduler, device)\n",
    "    valid_loss, valid_acc_1 = evaluate(model, valid_iterator, criterion, device)\n",
    "    \n",
    "    train_loss_lst.append(train_loss)\n",
    "    valid_loss_lst.append(valid_loss)\n",
    "    train_acc_lst.append(train_acc_1)\n",
    "    valid_acc_lst.append(valid_acc_1)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'stage1_best.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}% | ' )\n",
    "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}% | ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotTwinResults(ax, x_data, y_datas, x_label, y_labels, legend_loc, fig_title):\n",
    "    line1, = ax.plot(range(0,len(x_data)),y_datas[0], color='r', marker='.', label = y_labels[0])\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_labels[0], color='r')\n",
    "    ax2 = ax.twinx()\n",
    "    line2, = ax2.plot(range(0,len(x_data)),y_datas[1], color='b',  marker='x', label = y_labels[1])\n",
    "    ax2.set_ylabel(y_labels[1], color='b')\n",
    "    ax.set_title(fig_title)\n",
    "    \n",
    "    ax.legend(handles=[line1, line2], loc=legend_loc)\n",
    "    \n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ep_range = range(1,36)\n",
    "PlotTwinResults(ax[0], ep_range, [train_loss_lst, valid_loss_lst], 'No. of Epoch', \n",
    "                ['Training Loss', 'Validation Loss'],  'upper right', 'Change of Loss')\n",
    "\n",
    "PlotTwinResults(ax[1], ep_range, [train_acc_lst, valid_acc_lst], 'No. of Epoch', \n",
    "                ['Training Accuracy', 'Validation Accuracy'], 'lower right', 'Change of Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04009807",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('stage1_best.pt'))\n",
    "\n",
    "test_loss, test_acc_1  = evaluate(model, test_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc @1: {test_acc_1*100:6.2f}% | ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def get_predictions(model, iterator):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "    fnames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y, z) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim = -1)\n",
    "            top_pred = y_prob.argmax(1, keepdim = True)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "            fnames.extend([f for f in z])\n",
    "            \n",
    "\n",
    "    images = torch.cat(images, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "    probs = torch.cat(probs, dim = 0)\n",
    "#     fnames = torch.cat(fnames, dim = 0)\n",
    "\n",
    "    return images, labels, probs, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdab524",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, probs, fnames = get_predictions(model, test_iterator)\n",
    "pred_labels = torch.argmax(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76683ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(test_pred_output_dir):\n",
    "    os.makedirs(test_pred_output_dir)\n",
    "\n",
    "# output the prediction files of test set\n",
    "for fname, pred in zip(fnames, pred_labels):\n",
    "    fname = fname.split(\"\\\\\")[-1]\n",
    "    pf, sf = fname.split('.')\n",
    "    print(f'{fname} {classes[pred]}')\n",
    "    path = os.path.join(test_pred_output_dir, pf + '.txt')\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(classes[pred] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, pred_labels, classes):\n",
    "    \n",
    "    fig = plt.figure(figsize = (5, 5));\n",
    "    ax = fig.add_subplot(1, 1, 1);\n",
    "    cm = confusion_matrix(labels, pred_labels);\n",
    "    cm = ConfusionMatrixDisplay(cm, display_labels = classes);\n",
    "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
    "    fig.delaxes(fig.axes[1]) #delete colorbar\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.xlabel('Predicted Label', fontsize = 10)\n",
    "    plt.ylabel('True Label', fontsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea48cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(labels, pred_labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b53ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects = torch.eq(labels, pred_labels)\n",
    "\n",
    "incorrect_examples = []\n",
    "\n",
    "for image, label, prob, correct, fname in zip(images, labels, probs, corrects, fnames):\n",
    "    if not correct:\n",
    "        incorrect_examples.append((image, label, prob, fname))\n",
    "\n",
    "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96041312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_most_incorrect(incorrect, classes, n_images, normalize = True):\n",
    "    \n",
    "    n_images = len(incorrect) if n_images>len(incorrect) else n_images\n",
    "        \n",
    "\n",
    "    rows = math.ceil(np.sqrt(n_images))\n",
    "    cols = math.ceil(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize = (25, 20))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "        \n",
    "        if i < len(incorrect):\n",
    "\n",
    "            ax = fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "            image, true_label, probs, fname = incorrect[i]\n",
    "            fname = fname.split(\"\\\\\")[-1]\n",
    "            image = image.permute(1, 2, 0)\n",
    "            true_prob = probs[true_label]\n",
    "            incorrect_prob, incorrect_label = torch.max(probs, dim = 0)\n",
    "            true_class = classes[true_label]\n",
    "            incorrect_class = classes[incorrect_label]\n",
    "\n",
    "            if normalize:\n",
    "                image = normalize_image(image)\n",
    "\n",
    "            ax.imshow(image.cpu().numpy())\n",
    "            ax.set_title(f'true label: {true_class} ({true_prob:.3f})\\n' \\\n",
    "                         f'pred label: {incorrect_class} ({incorrect_prob:.3f})\\n' \\\n",
    "                         f'{fname}' )\n",
    "            ax.axis('off')\n",
    "        \n",
    "    fig.subplots_adjust(hspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 10\n",
    "\n",
    "plot_most_incorrect(incorrect_examples, classes, N_IMAGES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
