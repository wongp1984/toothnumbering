{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d619f2",
   "metadata": {},
   "source": [
    "# Stage 0 - Data Preparation\n",
    "\n",
    "This notebook is at Stage 0 of the tooth detection and numbering pipeline. It is going to prepare the images from the source to the formats suitable for subsequent stages of analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c603595",
   "metadata": {},
   "source": [
    "### 0. Process Zooniverse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import collections\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt  \n",
    "\n",
    "filename_classifications = 'tooth-numbering-workflow-classifications 20230725-20230824.csv'\n",
    "filename_output = 'classifications_flat_trim.csv'\n",
    "\n",
    "\n",
    "columns_out = ['classification_id', 'created_at', 'user_name', 'user_id',\n",
    "               'workflow_id', 'workflow_version', 'subject_ids', \n",
    "               'taskvalue_text', 'taskvalue_survey']\n",
    "\n",
    "\n",
    "# Reference: column names to choose from\n",
    "\n",
    "columns_in = ['classification_id', 'user_name', 'user_id', 'user_ip', \n",
    "              'workflow_id','workflow_name', 'workflow_version', 'created_at', \n",
    "              'gold_standard', 'expert', 'metadata', 'annotations', \n",
    "              'subject_data', 'subject_ids']\n",
    "       \n",
    "columns_new = ['metadata_json', 'annotations_json', 'subject_data_json', \n",
    "               'taskvalue_text', 'taskvalue_survey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d343baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = pd.read_csv(filename_classifications)\n",
    "classifications['metadata_json'] = [json.loads(q) for q in classifications.metadata]\n",
    "classifications['annotations_json'] = [json.loads(q) for q in classifications.annotations]\n",
    "classifications['subject_data_json'] = [json.loads(q) for q in classifications.subject_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a67af7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "taskvalue_survey =[]\n",
    "taskvalue_text = []\n",
    "\n",
    "zooniverse_output_label_ori_path = './ZooniverseOutput/labels_ori'\n",
    "zooniverse_output_label_YOLO_path = './ZooniverseOutput/labels_yolo'\n",
    "zooniverse_output_img_path = './ZooniverseOutput/annotatedimages'\n",
    "\n",
    "zooniverse_complete_img_path = './4 Private ZOON Anonymised/Bitewing_proc/images/Batch1_selected_NotYetAnnotated/AnnotatedonZooniverse'\n",
    "zooniverse_towork_img_path = './4 Private ZOON Anonymised/Bitewing_proc/images/Batch1_selected_NotYetAnnotated/UploadedZooniverse_(Tooth Numbering Subjects Selected 2nd Batch) 20230719'\n",
    "\n",
    "valid_lbls = ['t11','t12','t13','t14','t15','t16','t17','t18',\n",
    "              't21','t22','t23','t24','t25','t26','t27','t28',\n",
    "              't31','t32','t33','t34','t35','t36','t37','t38',\n",
    "              't41','t42','t43','t44','t45','t46','t47','t48']\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(zooniverse_output_label_ori_path):\n",
    "    os.makedirs(zooniverse_output_label_ori_path)\n",
    "    \n",
    "if not os.path.exists(zooniverse_output_label_YOLO_path):\n",
    "    os.makedirs(zooniverse_output_label_YOLO_path)\n",
    "    \n",
    "processed_imgs = []\n",
    "for i,row in classifications.iterrows():\n",
    "    img_file = [x['Filename'] for x in row['subject_data_json'].values()][0]\n",
    "    processed_imgs.append(img_file)\n",
    "annotation_counter = collections.Counter(processed_imgs)\n",
    "\n",
    "    \n",
    "    \n",
    "for i,row in classifications.iterrows():\n",
    "    \n",
    "    img_file = [x['Filename'] for x in row['subject_data_json'].values()][0]\n",
    "\n",
    "#     if (v:=annotation_counter.get(img_file, None))!=1:\n",
    "#         print(f'WARNING: {img_file} has been processed multiple {v} times. No annotation file will be generated')\n",
    "#         continuehttp://localhost:8888/notebooks/Documents/MSc/Dissertation/Dissertation%20Submission/dissertation_Stage0_DataPreparation.ipynb#\n",
    "        \n",
    "    is_valid_lbl = True\n",
    "    \n",
    "    output_YOLO_lines = ['YOLO_OBB\\n']\n",
    "    output_ori_lines = []\n",
    "\n",
    "    for annotation in row['annotations_json']:\n",
    "        \n",
    "        if len(annotation['value']) > 0:\n",
    "            for box in annotation['value']:\n",
    "                top_left_coor = np.array([ box['x'], box['y']] )\n",
    "                angle = box['angle']\n",
    "                \n",
    "                x1,y1 = float(box['x']), float(box['y'])\n",
    "                x2,y2 = x1+float(box['width']), y1+float(box['height'])\n",
    "                \n",
    "                xc,yc = round(0.5*(x1+x2),6), round(0.5*(y1+y2),6)\n",
    "                    \n",
    "                tooth_lbl = box['details'][0]['value'].strip()\n",
    "                tooth_lbl = 't' + tooth_lbl if tooth_lbl[0] != 't' else tooth_lbl\n",
    "                if tooth_lbl in valid_lbls:\n",
    "                    # YOLO_OBB = Label Index, x, y, H, W, Theta\n",
    "                    tooth_lbl = valid_lbls.index(tooth_lbl)\n",
    "                     \n",
    "                    # for YOLO, the angle is in reversed polarity\n",
    "                    line_yolo = str(tooth_lbl) + ' ' + str(xc) + ' ' + str(yc) + ' ' + \\\n",
    "                            str(round(box['width'],6)) + ' ' + str(round(box['height'],6)) + ' ' + str(-1*round(box['angle'],6)) + '\\n'\n",
    "\n",
    "                    output_YOLO_lines.append(line_yolo)\n",
    "                    \n",
    "                    line = str(tooth_lbl) + ' ' + str(box['x']) + ' ' + str(box['y']) + ' ' + \\\n",
    "                            str(round(box['width'],6)) + ' ' + str(round(box['height'],6)) + ' ' + str(round(box['angle'],6)) + '\\n'\n",
    "\n",
    "                    output_ori_lines.append(line)\n",
    "\n",
    "                else:\n",
    "                    is_valid_lbl = False\n",
    "                    print(f'WARNING: {img_file} --> {tooth_lbl} not valid! Annotation files will not be generated.')\n",
    "        else:\n",
    "            is_valid_lbl = False\n",
    "            print(f'WARNING: {img_file} has zero annotations. Annotation files will not be generated.')\n",
    "            \n",
    "    \n",
    "            \n",
    "    if is_valid_lbl:\n",
    "        pf, _ = img_file.split('.')\n",
    "\n",
    "        fname = pf+'.txt'\n",
    "        i = 1\n",
    "        while os.path.exists(os.path.join(zooniverse_output_label_YOLO_path, fname)):\n",
    "            fname = pf + '-' + str(i) + '.txt'\n",
    "            i +=1\n",
    "            \n",
    "        with open(os.path.join(zooniverse_output_label_YOLO_path, fname), 'w') as f:\n",
    "            f.writelines(output_YOLO_lines)\n",
    "            \n",
    "        i = 1\n",
    "        while os.path.exists(os.path.join(zooniverse_output_label_ori_path, fname)):\n",
    "            fname = pf + '-' + str(i) + '.txt'\n",
    "            i +=1\n",
    "            \n",
    "        with open(os.path.join(zooniverse_output_label_ori_path, fname), 'w') as f:\n",
    "            f.writelines(output_ori_lines)\n",
    "            \n",
    "        inpath = os.path.join(zooniverse_towork_img_path, img_file)\n",
    "        outpath = os.path.join(zooniverse_complete_img_path, img_file)\n",
    "        if os.path.exists(inpath):\n",
    "            shutil.move(inpath, outpath)\n",
    "            \n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abc447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the annotated files\n",
    "\n",
    "# https://stackoverflow.com/questions/34372480/rotate-point-about-another-point-in-degrees-python\n",
    "def rotate(point, origin, angle):\n",
    "    \"\"\"\n",
    "    Rotate a point counterclockwise by a given angle around a given origin.\n",
    "    \n",
    "    The angle should be given in radians.\n",
    "    \"\"\"\n",
    "    ox, oy = origin\n",
    "    px, py = point\n",
    "\n",
    "    qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)\n",
    "    qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)\n",
    "    return qx, qy\n",
    "\n",
    "def rotate_box(box, angle):\n",
    "    # input box is [x1, y1, x2, y2], angle is in degree\n",
    "    # return rotate output box (coordinates of 4 points [top left, top right, bottom right, bottom left])\n",
    "    x1, y1, x2, y2 = box\n",
    "    angle = math.radians(angle) # convert to radian\n",
    "\n",
    "    tl = (x1, y1)\n",
    "    tr = (x2, y1)\n",
    "    br = (x2, y2)\n",
    "    bl = (x1, y2)\n",
    "    center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "    \n",
    "    tl = rotate(tl, center, angle)\n",
    "    tr = rotate(tr, center, angle)\n",
    "    br = rotate(br, center, angle)\n",
    "    bl = rotate(bl, center, angle)\n",
    "    return tl, tr, br, bl\n",
    "\n",
    "\n",
    "if not os.path.exists(zooniverse_output_img_path):\n",
    "    os.makedirs(zooniverse_output_img_path)\n",
    "    \n",
    "\n",
    "for path in os.listdir(zooniverse_complete_img_path):\n",
    "    pf, sf = path.split('.')\n",
    "    \n",
    "    img = cv2.imread(os.path.join(zooniverse_complete_img_path, path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    label_fname = pf+'.txt'\n",
    "    i = 1\n",
    "    while os.path.exists(os.path.join(zooniverse_output_label_ori_path, label_fname)):            \n",
    "            \n",
    "        dimg = img.copy()\n",
    "        with open(os.path.join(zooniverse_output_label_ori_path, label_fname), 'r') as f:\n",
    "            rows = f.readlines()\n",
    "            for row in rows:\n",
    "                if row.strip()!='YOLO_OBB':\n",
    "                    row = row.split(' ')\n",
    "                    x1,y1 = float(row[1]), float(row[2])\n",
    "                    x2,y2 = float(row[1])+float(row[3]), float(row[2])+float(row[4])\n",
    "                    rotated_box = np.asarray(rotate_box([x1,y1,x2,y2], float(row[5])), dtype=int)\n",
    "                    tooth_lbl = valid_lbls[int(row[0])]\n",
    "\n",
    "                    dimg = cv2.drawContours(dimg, [rotated_box], 0, color=(255,0,0), thickness=4)\n",
    "\n",
    "                    dimg = cv2.putText(img=dimg, text=tooth_lbl, org=np.array([(x1+x2)/2, (y1+y2)/2], dtype=int), fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       fontScale=1, color=(255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "                    img_fname = pf + '.png'\n",
    "                    cv2.imwrite(os.path.join(zooniverse_output_img_path, img_fname), dimg)\n",
    "                 \n",
    "        pf = pf + '-' + str(i)\n",
    "        label_fname = pf + '.txt'\n",
    "        i +=1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848edc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we need to manually check the annotated image files and delete those not suitable for analysis\n",
    "# Check multiple annotated files, delete the duplicated annotations, and retain the final version\n",
    "import os\n",
    "import shutil\n",
    "zooniverse_img_path = './ZooniverseOutput/annotatedimages'\n",
    "zooniverse_label_path = './ZooniverseOutput/labels_yolo'\n",
    "zooniverse_dedup_label_path = './ZooniverseOutput/dedup_labels_yolo'\n",
    "\n",
    "if not os.path.exists(zooniverse_dedup_label_path):\n",
    "    os.makedirs(zooniverse_dedup_label_path)\n",
    "\n",
    "for path in os.listdir(zooniverse_img_path):\n",
    "    pf, sf = path.split('.')\n",
    "    inpath = os.path.join(zooniverse_label_path, pf + '.txt')\n",
    "    \n",
    "    pf2, *sf2 = pf.split('-')\n",
    "    \n",
    "    if sf2 is not None:\n",
    "        print(f'Renamed {pf} to {pf2}')\n",
    "    outpath = os.path.join(zooniverse_dedup_label_path, pf2 + '.txt')\n",
    "    \n",
    "    if os.path.exists(inpath):\n",
    "        shutil.copy(inpath, outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69177730",
   "metadata": {},
   "source": [
    "### 1. JPEG to PNG Conversion\n",
    "It is important to change all images to the same size for labelling, also resize for uploading to Zooniverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ac32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# source image folder path\n",
    "dir_path = './4 Private ZOON Anonymised/Bitewing'\n",
    "\n",
    "# all converted images in PNG format were saved the result_path \n",
    "result_path = './4 Private ZOON Anonymised/Bitewing_proc'\n",
    "\n",
    "\n",
    "def resize_add_margin(inpath, outpath, paddedlogpath):\n",
    "    pil_img = Image.open(inpath)\n",
    "    \n",
    "    # convert to grayscale \n",
    "    pil_img = pil_img.convert('L')\n",
    "    \n",
    "    fsize =  os.stat(inpath).st_size\n",
    "   \n",
    "    # resize large image\n",
    "    if fsize > 1e6:\n",
    "        resizefactor = 0.8/(fsize/1e6)\n",
    "        print(f'{inpath} -- {fsize} too large.')\n",
    "        w, h = pil_img.size\n",
    "        newsize = (round(w*resizefactor), round(h*resizefactor))\n",
    "        pil_img = pil_img.resize(newsize)\n",
    "        \n",
    "    # Pad zeros on both sides to faciliate rotated bounding boxes in Zooniverse\n",
    "    width, height = pil_img.size\n",
    "    xpads = round(width/7)\n",
    "    ypads = round(height/8)\n",
    "    \n",
    "    new_width = width + 2*xpads \n",
    "    new_height = height + 2*ypads\n",
    "    \n",
    "    result = Image.new(pil_img.mode, (new_width, new_height), (255,))\n",
    "    \n",
    "    result.paste(pil_img, (xpads, ypads))\n",
    "    \n",
    "    result.save(outpath, quality=95)\n",
    "    \n",
    "    with open(paddedlogpath, 'w') as f:\n",
    "        f.write(f'{xpads} {ypads} {width} {height}')\n",
    "    \n",
    "\n",
    "for path in os.listdir(dir_path):\n",
    "    pf, sf = path.split('.')\n",
    "    inpath = os.path.join(dir_path, path)\n",
    "    outpath = os.path.join(result_path, pf + '.png')\n",
    "    paddedlogpath = os.path.join(result_path, pf + '.pad.log')\n",
    "    resize_add_margin(inpath, outpath, paddedlogpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46f930",
   "metadata": {},
   "source": [
    "### 2. Convert Annotation Files from YOLO format to DOTA format\n",
    "\n",
    "The annotation label files are in YOLO format. The YOLO Oriented Bounding Box model requires DOTA format. So it is required to convert the label files to DOTA. Before conversion, it is required to have a validity check of all the labels to ensure its validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math \n",
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "import shutil\n",
    "import torchvision\n",
    "\n",
    "# 32cls_path for 32 tooth classes in YOLO format. \n",
    "# 4cls_path for 4 tooth classes (Upper/Lower x Molar/Nonmolar) in YOLO format\n",
    "image_folder_path = './4 Private ZOON Anonymised/Bitewing_proc/images'\n",
    "\n",
    "# Annotation files converted and deduplicated from Zooniverse (zooniverse_dedup_label_path) should be accumulatedly placed here\n",
    "labelImg_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/data_labelImg_OBB_accumulated'\n",
    "\n",
    "\n",
    "train_img_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/train/images'\n",
    "train_label_32cls_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/train/labelTxt_32Cls'\n",
    "train_label_4cls_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/train/labelTxt_4Cls'\n",
    "train_label_16cls_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/train/labelTxt_16Cls'\n",
    "\n",
    "val_img_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/val/images'\n",
    "val_label_32cls_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/val/labelTxt_32Cls'\n",
    "val_label_4cls_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/val/labelTxt_4Cls'\n",
    "val_label_16cls_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/val/labelTxt_16Cls'\n",
    "\n",
    "labelfile = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/classes.txt'\n",
    "\n",
    "\n",
    "valid_lbls = ['t11','t12','t13','t14','t15','t16','t17','t18',\n",
    "              't21','t22','t23','t24','t25','t26','t27','t28',\n",
    "              't31','t32','t33','t34','t35','t36','t37','t38',\n",
    "              't41','t42','t43','t44','t45','t46','t47','t48']\n",
    "\n",
    "\n",
    "class_map_4classes = {'t11':'U_nonmolar','t12':'U_nonmolar','t13':'U_nonmolar','t14':'U_nonmolar','t15':'U_nonmolar',\n",
    "                      't16':'U_molar','t17':'U_molar','t18':'U_molar',\n",
    "                      't21':'U_nonmolar','t22':'U_nonmolar','t23':'U_nonmolar','t24':'U_nonmolar','t25':'U_nonmolar',\n",
    "                      't26':'U_molar','t27':'U_molar','t28':'U_molar',\n",
    "                      't31':'L_nonmolar','t32':'L_nonmolar','t33':'L_nonmolar','t34':'L_nonmolar','t35':'L_nonmolar',\n",
    "                      't36':'L_molar','t37':'L_molar','t38':'L_molar',\n",
    "                      't41':'L_nonmolar','t42':'L_nonmolar','t43':'L_nonmolar','t44':'L_nonmolar','t45':'L_nonmolar',\n",
    "                      't46':'L_molar','t47':'L_molar','t48':'L_molar'}\n",
    "\n",
    "\n",
    "class_map_16classes = {'t11':'U1','t12':'U2','t13':'U3','t14':'U4','t15':'U5',\n",
    "                      't16':'U6','t17':'U7','t18':'U8',\n",
    "                      't21':'U1','t22':'U2','t23':'U3','t24':'U4','t25':'U5',\n",
    "                      't26':'U6','t27':'U7','t28':'U8',\n",
    "                      't31':'L1','t32':'L2','t33':'L3','t34':'L4','t35':'L5',\n",
    "                      't36':'L6','t37':'L7','t38':'L8',\n",
    "                      't41':'L1','t42':'L2','t43':'L3','t44':'L4','t45':'L5',\n",
    "                      't46':'L6','t47':'L7','t48':'L8'}\n",
    "\n",
    "\n",
    "if not os.path.exists(train_img_path):\n",
    "    os.makedirs(train_img_path)\n",
    "    \n",
    "if not os.path.exists(train_label_32cls_path):\n",
    "    os.makedirs(train_label_32cls_path)\n",
    "\n",
    "if not os.path.exists(train_label_4cls_path):\n",
    "    os.makedirs(train_label_4cls_path)\n",
    "    \n",
    "if not os.path.exists(train_label_16cls_path):\n",
    "    os.makedirs(train_label_16cls_path)\n",
    "    \n",
    "if not os.path.exists(val_img_path):\n",
    "    os.makedirs(val_img_path)\n",
    "    \n",
    "    \n",
    "if not os.path.exists(val_label_32cls_path):\n",
    "    os.makedirs(val_label_32cls_path)\n",
    "    \n",
    "if not os.path.exists(val_label_4cls_path):\n",
    "    os.makedirs(val_label_4cls_path)\n",
    "    \n",
    "if not os.path.exists(val_label_16cls_path):\n",
    "    os.makedirs(val_label_16cls_path)\n",
    "    \n",
    "    \n",
    "with open(labelfile, 'r') as f:\n",
    "    labels = [s.strip() for s in f.readlines()]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This checks the validity of labels\n",
    "\n",
    "filelist = []\n",
    "\n",
    "for path in os.listdir(labelImg_path):\n",
    "# check if current path is a file\n",
    "    if os.path.isfile(os.path.join(labelImg_path, path)):\n",
    "        filelist.append(path)\n",
    "        \n",
    "\n",
    "is_invalid_lbl = False\n",
    "\n",
    "for path in filelist: \n",
    "    with open(os.path.join(labelImg_path, path), 'r') as f:\n",
    "        ann_points = f.readlines()\n",
    "        \n",
    "        list_lbl = []\n",
    "        for row in ann_points[1:]:\n",
    "            row = row.split()\n",
    "            \n",
    "            lbl = labels[int(row[0])]\n",
    "            # check the validity of labels. If not valid, quit.\n",
    "            if lbl not in valid_lbls:\n",
    "                print(f'WARNING! {path} contains invalid label {lbl}')\n",
    "                is_invalid_lbl = True\n",
    "            else:\n",
    "                list_lbl.append(lbl)\n",
    "                \n",
    "        c = collections.Counter(list_lbl)\n",
    "        for k,v in c.items():\n",
    "            if v > 1:\n",
    "                is_invalid_lbl = True\n",
    "                print(f'WARNING! {path} contains duplicated label {k}')\n",
    "                \n",
    "        # this checks contradicting labels, e.g. t23 and t14 exists at the same time.\n",
    "        quads = [s[0:2] for s in list_lbl]\n",
    "        quads = ''.join(list(set(quads)))\n",
    "        if len(quads)>2 and (quads != 't1t4' and quads != 't4t1' and quads != 't2t3' and quads != 't3t2'):\n",
    "            print(f'WARNING! {path} contains invalid labels in contradicting quadrants {quads}')\n",
    "            is_invalid_lbl = True\n",
    "            \n",
    "\n",
    "if is_invalid_lbl:\n",
    "    print('Invalid labels found. Please rectify before continuing.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f60d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://mmrotate.readthedocs.io/en/latest/intro.html\n",
    "#https://mmrotate.readthedocs.io/en/latest/tutorials/customize_dataset.html\n",
    "\n",
    "# YOLO_OBB = Label Index, x, y, H, W, Theta\n",
    "# DOTA = xA,yA, xB,yB, xC,yC, xD,yD, Category, Difficulty \n",
    "\n",
    "samplelabels = {'train': [], 'val': []}\n",
    "\n",
    "random.seed(721)\n",
    "\n",
    "\n",
    "# sort coordinates in counterclockwise order https://pavcreations.com/clockwise-and-counterclockwise-sorting-of-coordinates/\n",
    "def sort_coordinates(list_of_xy_coords, is_clockwise):\n",
    "    cx, cy = list_of_xy_coords.mean(0)\n",
    "    x, y = list_of_xy_coords.T\n",
    "    angles = np.arctan2(x-cx, y-cy)\n",
    "    indices = np.argsort(-1*angles) if is_clockwise else np.argsort(angles)\n",
    "    \n",
    "    return list_of_xy_coords[indices]\n",
    " \n",
    "trainlist = random.sample(filelist, round(0.7*len(filelist)))\n",
    "\n",
    "if not is_invalid_lbl:\n",
    "    \n",
    "    for path in filelist:\n",
    "\n",
    "        rows_dota_32cls = []    \n",
    "        rows_dota_4cls = []\n",
    "        rows_dota_16cls = []\n",
    "   \n",
    "        \n",
    "        with open(os.path.join(labelImg_path, path), 'r') as f:\n",
    "            ann_points = f.readlines()\n",
    "\n",
    "            # map points to different classes combinations\n",
    "            for row in ann_points[1:]:\n",
    "                row = row.split()\n",
    "                # lbl = int(labels[int(row[0])])\n",
    "\n",
    "                lbl = labels[int(row[0])]\n",
    "\n",
    "                # check the validity of labels. If not valid, quit.\n",
    "                if lbl not in valid_lbls:\n",
    "                    print(f'WARNING! {path} contains invalid label {lbl}')\n",
    "\n",
    "                lbl_4cls = class_map_4classes[lbl]\n",
    "                lbl_16cls = class_map_16classes[lbl]\n",
    "\n",
    "                if path in trainlist:\n",
    "                    samplelabels['train'].append(lbl)\n",
    "                else:\n",
    "                    samplelabels['val'].append(lbl)\n",
    "\n",
    "                center = np.array([float(row[1]),float(row[2])])\n",
    "                w_h = np.array([float(row[3]),float(row[4])])\n",
    "\n",
    "                theta = np.radians(float(row[5]))\n",
    "\n",
    "                rotate_mat = np.zeros([2,2])\n",
    "                rotate_mat[0] = np.array([np.cos(theta), np.sin(theta)])\n",
    "                rotate_mat[1] = np.array([-1*np.sin(theta), np.cos(theta)])\n",
    "\n",
    "                coor_A = np.around(center + np.matmul(rotate_mat,w_h*np.array([-0.5,-0.5]))).astype(int)\n",
    "                coor_B = np.around(center + np.matmul(rotate_mat,w_h*np.array([-0.5,0.5]))).astype(int)\n",
    "                coor_C = np.around(center + np.matmul(rotate_mat,w_h*np.array([0.5,0.5]))).astype(int)\n",
    "                coor_D = np.around(center + np.matmul(rotate_mat,w_h*np.array([0.5,-0.5]))).astype(int)\n",
    "\n",
    "                # sort the coordinates in clockwise manner\n",
    "                row_c = np.array([coor_A, coor_B, coor_C, coor_D])\n",
    "                row_c = sort_coordinates(row_c, is_clockwise=True)\n",
    "\n",
    "                # shift the topleft corner to closest to origin\n",
    "                shift = np.argmin(np.sum(row_c*row_c,axis=1))\n",
    "                row_c = np.roll(row_c , -1*shift, axis=0).flatten()\n",
    "\n",
    "                # set difficulty to 0\n",
    "                row_c_32cls = ' '.join([*[str(r) for r in row_c], str(lbl), str(0)]) + '\\n'\n",
    "                rows_dota_32cls.append(row_c_32cls)\n",
    "\n",
    "                row_c_4cls = ' '.join([*[str(r) for r in row_c], str(lbl_4cls), str(0)]) + '\\n'\n",
    "                rows_dota_4cls.append(row_c_4cls)\n",
    "                \n",
    "                row_c_16cls = ' '.join([*[str(r) for r in row_c], str(lbl_16cls), str(0)]) + '\\n'\n",
    "                rows_dota_16cls.append(row_c_16cls)\n",
    "\n",
    "\n",
    "        # only write converted format if len(rows_dota) > 0\n",
    "        if len(rows_dota_32cls) > 0:\n",
    "           \n",
    "            prefix, suffix = path.split('.')\n",
    "            imagename = prefix + '.png'\n",
    "\n",
    "            if path in trainlist:\n",
    "                with open(os.path.join(train_label_32cls_path, path), 'a') as f:\n",
    "                    f.writelines(rows_dota_32cls)\n",
    "\n",
    "                with open(os.path.join(train_label_4cls_path, path), 'a') as f:\n",
    "                    f.writelines(rows_dota_4cls)\n",
    "                    \n",
    "                with open(os.path.join(train_label_16cls_path, path), 'a') as f:\n",
    "                    f.writelines(rows_dota_16cls)\n",
    "\n",
    "\n",
    "                # copy the image file to training image folder   \n",
    "                for p in os.listdir(image_folder_path):\n",
    "                    p = os.path.join(image_folder_path, p)\n",
    "                    if not os.path.isfile(p):\n",
    "                        if os.path.exists(os.path.join(p, imagename)):\n",
    "                            shutil.copyfile(os.path.join(p, imagename), os.path.join(train_img_path, imagename))\n",
    "                            break\n",
    "\n",
    "            else:\n",
    "                with open(os.path.join(val_label_32cls_path, path), 'a') as f:\n",
    "                    f.writelines(rows_dota_32cls)\n",
    "\n",
    "                with open(os.path.join(val_label_4cls_path, path), 'a') as f:\n",
    "                    f.writelines(rows_dota_4cls)\n",
    "                    \n",
    "                with open(os.path.join(val_label_16cls_path, path), 'a') as f:\n",
    "                    f.writelines(rows_dota_16cls)\n",
    "\n",
    "\n",
    "                # copy the image file to val image folder            \n",
    "                for p in os.listdir(image_folder_path):\n",
    "                    p = os.path.join(image_folder_path, p)\n",
    "                    if not os.path.isfile(p):\n",
    "                        if os.path.exists(os.path.join(p, imagename)):\n",
    "                            shutil.copyfile(os.path.join(p, imagename), os.path.join(val_img_path, imagename))\n",
    "                            break\n",
    "\n",
    "\n",
    "    c = collections.Counter(samplelabels['train'])\n",
    "    myKeys = list(c.keys())\n",
    "    myKeys.sort()\n",
    "    sorted_dict_train = {i: c[i] for i in myKeys}\n",
    "\n",
    "    c = collections.Counter(samplelabels['val'])\n",
    "    myKeys = list(c.keys())\n",
    "    myKeys.sort()\n",
    "    sorted_dict_val = {i: c[i] for i in myKeys}\n",
    "\n",
    "    label_count = {}\n",
    "\n",
    "    for i in valid_lbls:\n",
    "        label_count[i] = sorted_dict_train.get(i,0) + sorted_dict_val.get(i,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "xx = []\n",
    "xx.extend(['Top Left' for i in range(0,8)])\n",
    "xx.extend(['Top Right' for i in range(0,8)])\n",
    "xx.extend(['Bottom Right' for i in range(0,8)])\n",
    "xx.extend(['Bottom Left' for i in range(0,8)])\n",
    "\n",
    "data = {'Quadrant name':xx,\n",
    "        'Tooth number':label_count.keys(),\n",
    "        'count':label_count.values()}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "ax = sns.barplot(x='Tooth number', y='count', data=df, hue='Quadrant name', dodge=False)\n",
    "plt.title(\"Annotation Frequency of Tooth Numbers\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a606a3e8",
   "metadata": {},
   "source": [
    "### 3. Prepare Dataset for Stage 1 Left/Right Quadrant Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50db188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/bentrevett/pytorch-image-classification/blob/master/5_resnet.ipynb\n",
    "\n",
    "# DOTA = xA,yA, xB,yB, xC,yC, xD,yD, Category, Difficulty \n",
    "\n",
    "import os\n",
    "import math \n",
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "import shutil\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def flip_merge(img):\n",
    "    \n",
    "    width, height = img.size\n",
    "    if width < height:\n",
    "        img = img.transpose(Image.ROTATE_90)\n",
    "        width, height = img.size\n",
    "\n",
    "    flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    result = Image.new(img.mode, (2*width, height), (255,))\n",
    "    result.paste(img, (0, 0))\n",
    "    result.paste(flipped_img, (width, 0))   \n",
    "    w, h = result.size\n",
    "    \n",
    "    result = result.resize((224, 224))\n",
    "    \n",
    "    return result \n",
    "\n",
    "\n",
    "random.seed(721)\n",
    "\n",
    "res = []\n",
    "\n",
    "\n",
    "labelfile = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/classes.txt'\n",
    "\n",
    "train_label_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/train/labelTxt_32Cls'\n",
    "train_image_folder_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/train/images'\n",
    "train_class_left_dataset_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage1_dataset_LR_classifier/train/LEFT'\n",
    "train_class_right_dataset_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage1_dataset_LR_classifier/train/RIGHT'\n",
    "\n",
    "test_label_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/val/labelTxt_32Cls'\n",
    "test_image_folder_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage2_yolo_obb/val/images'\n",
    "test_class_left_dataset_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage1_dataset_LR_classifier/test/LEFT'\n",
    "test_class_right_dataset_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial9XX/Stage1_dataset_LR_classifier/test/RIGHT'\n",
    "\n",
    "label_paths = [train_label_path, test_label_path]\n",
    "image_paths = [train_image_folder_path, test_image_folder_path]\n",
    "left_paths = [train_class_left_dataset_path, test_class_left_dataset_path]\n",
    "right_paths = [train_class_right_dataset_path, test_class_right_dataset_path]\n",
    "\n",
    "total_right_cnt = 0 \n",
    "total_left_cnt = 0\n",
    "\n",
    "for lbl_path, img_path, cls_l_path, cls_r_path in zip(label_paths,image_paths,left_paths,right_paths):\n",
    "    \n",
    "    if not os.path.exists(cls_l_path):\n",
    "        os.makedirs(cls_l_path)\n",
    "\n",
    "    if not os.path.exists(cls_r_path):\n",
    "        os.makedirs(cls_r_path)\n",
    "\n",
    "    with open(labelfile, 'r') as f:\n",
    "        labels = [s.strip() for s in f.readlines()]\n",
    "\n",
    "\n",
    "    filelist = []\n",
    "    for path in os.listdir(lbl_path):\n",
    "    # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(lbl_path, path)):\n",
    "            filelist.append(path)\n",
    "\n",
    "    transform = transforms.Grayscale(num_output_channels=3)\n",
    "\n",
    "    for path in filelist:\n",
    "\n",
    "        rows_dota = []\n",
    "        right_lbl_cnt = 0\n",
    "        left_lbl_cnt = 0\n",
    "        with open(os.path.join(lbl_path, path), 'r') as f:\n",
    "            ann_points = f.readlines()\n",
    "            for row in ann_points[1:]:\n",
    "                row = row.split()\n",
    "                # lbl = int(labels[int(row[0])])\n",
    "                #lbl = labels[int(row[0])]\n",
    "                lbl = row[8]\n",
    "                if lbl in ['t11','t12','t13','t14','t15','t16','t17','t18'] or \\\n",
    "                    lbl in ['t41','t42','t43','t44','t45','t46','t47','t48']:\n",
    "                    right_lbl_cnt += 1\n",
    "\n",
    "                if lbl in ['t31','t32','t33','t34','t35','t36','t37','t38'] or \\\n",
    "                    lbl in ['t21','t22','t23','t24','t25','t26','t27','t28']:\n",
    "                    left_lbl_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "        # only write converted format if len(rows_dota) > 0\n",
    "\n",
    "        prefix, suffix = path.split('.')\n",
    "        imagename = prefix + '.png'\n",
    "\n",
    "        img = Image.open(os.path.join(img_path, imagename))\n",
    "\n",
    "        # convert image to 3-channel RGB for simple classification using Resnet\n",
    "        img = transform(img)\n",
    "        \n",
    "        \n",
    "        # randomly rotate the images.\n",
    "        rotate = random.sample([0,1,2,3],1)[0]\n",
    "        if rotate == 1:\n",
    "            img = img.transpose(Image.ROTATE_90)\n",
    "        elif rotate == 2:\n",
    "            img = img.transpose(Image.ROTATE_180)\n",
    "        elif rotate == 3:\n",
    "            img = img.transpose(Image.ROTATE_270)\n",
    "            \n",
    "\n",
    "        if right_lbl_cnt > left_lbl_cnt:\n",
    "            # Save the image file to RIGHT classe folder            \n",
    "            img.save(os.path.join(cls_r_path, imagename), quality=95)\n",
    "            total_right_cnt += 1\n",
    "\n",
    "        elif left_lbl_cnt > right_lbl_cnt:\n",
    "            # copy the image file to LEFT classe folder            \n",
    "            img.save(os.path.join(cls_l_path, imagename), quality=95)\n",
    "            total_left_cnt += 1\n",
    "    \n",
    "                \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d39f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff3bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5e9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
