{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a1ddbfe",
   "metadata": {},
   "source": [
    "# Stage 3 - Tooth Distance Classifiers\n",
    "\n",
    "In the classification outcomes from the previous stages, the search space of tooth numbers is effectively narrowed down. Given the locations of molar and non-molar teeth, one can now try to estimate their tooth numbers by considering the natural tooth sequence, tooth sizes, and their relative positions. In this stage, this heuristic estimation is implemented using a number of Random Forest (RF) or Support Vector Machine (SVM) classifiers using the Scikit-Learn module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68626f46",
   "metadata": {},
   "source": [
    "### Calculate the dataset of teeth bounding box distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564dd6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math \n",
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "import shutil\n",
    "import torchvision\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "train_img_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/train/images'\n",
    "train_label_32cls_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/train/labelTxt_32Cls'\n",
    "\n",
    "val_img_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/val/images'\n",
    "val_label_32cls_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/val/labelTxt_32Cls'\n",
    "\n",
    "nonmolar_lbls = ['t11','t12','t13','t14','t15',\n",
    "                 't41','t42','t43','t44','t45', \n",
    "                 't21','t22','t23','t24','t25',\n",
    "                 't31','t32','t33','t34','t35']\n",
    "\n",
    "molar_lbls = ['t16','t17','t18',\n",
    "              't46','t47','t48',\n",
    "              't26','t27','t28',\n",
    "              't36','t37','t38']\n",
    "\n",
    "valid_lbls = ['t11','t12','t13','t14','t15','t16','t17','t18',\n",
    "              't21','t22','t23','t24','t25','t26','t27','t28',\n",
    "              't31','t32','t33','t34','t35','t36','t37','t38',\n",
    "              't41','t42','t43','t44','t45','t46','t47','t48']\n",
    "\n",
    "padding_log_path = './4 Private ZOON Anonymised/Bitewing_proc/paddinglogs'\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646cb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "def CreateTeethDistanceAndWidthData(data_label_path, image_path):\n",
    "    teeth_distances = {}\n",
    "    for path in os.listdir(data_label_path):\n",
    "\n",
    "        pf, sf = path.split('.')\n",
    "        pil_img = Image.open(os.path.join(image_path, pf + '.png'))\n",
    "        \n",
    "        img_diag = (pil_img.size[0]**2 + pil_img.size[1]**2)**0.5\n",
    "#         img_diag = img_diag_with_no_pad[pf] \n",
    "\n",
    "        path = os.path.join(data_label_path, path)\n",
    "        if os.path.isfile(path):\n",
    "            with open(path, 'r') as f:\n",
    "                box_coors = {}\n",
    "                ann_points = f.readlines()\n",
    "\n",
    "                for row in ann_points:\n",
    "                    row = row.split()\n",
    "                    lbl = row[8]\n",
    "\n",
    "                    coor1 = np.array([int(row[0]), int(row[1])])\n",
    "                    coor2 = np.array([int(row[2]), int(row[3])])\n",
    "                    coor3 = np.array([int(row[4]), int(row[5])])\n",
    "                    coor4 = np.array([int(row[6]), int(row[7])])\n",
    "\n",
    "                    # assume the rectangle coordinates in clockwise arrangement, calculate the centre using opposite corners\n",
    "                    center = 0.5*(coor1 + coor3)\n",
    "                    \n",
    "                    w1 = np.linalg.norm(coor1-coor2)/img_diag\n",
    "                    w2 = np.linalg.norm(coor2-coor3)/img_diag\n",
    "                    width = min(w1,w2)\n",
    "                    \n",
    "                    \n",
    "                    corners = np.array([[int(row[0]), int(row[1])], [int(row[2]), int(row[3])], \n",
    "                                       [int(row[4]), int(row[5])], [int(row[6]), int(row[7])]])\n",
    "                    \n",
    "#                     box_coors[lbl] = center\n",
    "                    box_coors[lbl] = [center, width, corners]\n",
    "    \n",
    "\n",
    "\n",
    "        for ln,t in box_coors.items():\n",
    "            if ln in valid_lbls:\n",
    "                for lm in valid_lbls:\n",
    "                    u = box_coors.get(lm,None)\n",
    "                    if u is not None:\n",
    "                        label = ln + '_' + lm\n",
    "                        dist = np.linalg.norm(t[0]-u[0])\n",
    "\n",
    "                        # Normalize by image diagonal length\n",
    "                        dist = dist/img_diag\n",
    "                                   \n",
    "                        r1 = Polygon(t[2])\n",
    "                        r2 = Polygon(u[2])\n",
    "                        iou = r1.intersection(r2).area / r1.union(r2).area \n",
    "                        \n",
    "                        if iou>0.12 :\n",
    "                            if abs(int(ln[-1]) - int(lm[-1])) == 1 and ln[0:2]==lm[0:2]:\n",
    "                                print(f'***{pf} {label} {iou}')\n",
    "\n",
    "                        if (dist_list:=teeth_distances.get(label, None)) is None:\n",
    "                            teeth_distances[label] = [[dist, t[1], u[1], iou]]\n",
    "                        else:\n",
    "                            dist_list.append([dist, t[1], u[1], iou])\n",
    "                            \n",
    "    merged_teeth_distances = {}\n",
    "    for n in range(1,9):\n",
    "        for m in range(1,9):\n",
    "\n",
    "            # both Upper left and Upper right quadrants are merged together as they are simply mirrored \n",
    "            upperlbl = 'U' + str(n) + '_' + 'U' + str(m)\n",
    "            lbl = 't' + str(10+n) + '_' + 't' + str(10+m)\n",
    "            if (lst := teeth_distances.get(lbl,None)) is not None:\n",
    "                merged_teeth_distances[upperlbl] = copy.deepcopy(lst)\n",
    "            lbl = 't' + str(20+n) + '_' + 't' + str(20+m)\n",
    "            if (lst := teeth_distances.get(lbl,None)) is not None:\n",
    "                if merged_teeth_distances.get(upperlbl,None) is not None:\n",
    "                    merged_teeth_distances[upperlbl].extend(copy.deepcopy(lst))\n",
    "                else:\n",
    "                    merged_teeth_distances[upperlbl] = copy.deepcopy(lst)\n",
    "                    \n",
    "\n",
    "            # both Lower left and Lower right quadrants are merged together as they are simply mirrored     \n",
    "            lowerlbl = 'L' + str(n) + '_' + 'L' + str(m)\n",
    "            lbl = 't' + str(30+n) + '_' + 't' + str(30+m)\n",
    "            if (lst := teeth_distances.get(lbl,None)) is not None:\n",
    "                merged_teeth_distances[lowerlbl] = copy.deepcopy(lst)\n",
    "            lbl = 't' + str(40+n) + '_' + 't' + str(40+m)\n",
    "            if (lst := teeth_distances.get(lbl,None)) is not None:\n",
    "                if merged_teeth_distances.get(lowerlbl,None) is not None:\n",
    "                    merged_teeth_distances[lowerlbl].extend(copy.deepcopy(lst))\n",
    "                else:\n",
    "                    merged_teeth_distances[lowerlbl] = copy.deepcopy(lst)\n",
    "\n",
    "            # Lower  and Upper      \n",
    "            crosslbl = 'L' + str(n) + '_' + 'U' + str(m)\n",
    "            lbl = 't' + str(40+n) + '_' + 't' + str(10+m)\n",
    "            if (lst := teeth_distances.get(lbl,None)) is not None:\n",
    "                merged_teeth_distances[crosslbl] = copy.deepcopy(lst)\n",
    "            lbl = 't' + str(30+n) + '_' + 't' + str(20+m)\n",
    "            if (lst := teeth_distances.get(lbl,None)) is not None:\n",
    "                if merged_teeth_distances.get(crosslbl, None) is not None:\n",
    "                    merged_teeth_distances[crosslbl].extend(copy.deepcopy(lst))\n",
    "                else:\n",
    "                    merged_teeth_distances[crosslbl] = copy.deepcopy(lst)\n",
    "\n",
    "            # Upper  and Lower      \n",
    "            crosslbl = 'U' + str(n) + '_' + 'L' + str(m)\n",
    "            lbl = 't' + str(10+n) + '_' + 't' + str(40+m)\n",
    "            if (lst := teeth_distances.get(lbl,None)) is not None:\n",
    "                merged_teeth_distances[crosslbl] = copy.deepcopy(lst)\n",
    "            lbl = 't' + str(20+n) + '_' + 't' + str(30+m)\n",
    "            if (lst := teeth_distances.get(lbl,None)) is not None:\n",
    "                if merged_teeth_distances.get(crosslbl, None) is not None:\n",
    "                    merged_teeth_distances[crosslbl].extend(copy.deepcopy(lst))\n",
    "                else:\n",
    "                    merged_teeth_distances[crosslbl] = copy.deepcopy(lst)\n",
    "                    \n",
    "    return merged_teeth_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b3765",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_teeth_distancesAndwidths = CreateTeethDistanceAndWidthData(train_label_32cls_path, train_img_path)\n",
    "test_teeth_distancesAndwidths = CreateTeethDistanceAndWidthData(val_label_32cls_path, val_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dff10b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def CreateTeethWidthData(data_label_path, image_path):\n",
    "    teeth_widths = {}\n",
    "    for path in os.listdir(data_label_path):\n",
    "\n",
    "        pf, sf = path.split('.')\n",
    "        pil_img = Image.open(os.path.join(image_path, pf + '.png'))\n",
    "        img_diag = (pil_img.size[0]**2 + pil_img.size[1]**2)**0.5\n",
    "        \n",
    "#         print(f'{path} {pil_img.size}' )\n",
    "\n",
    "        path = os.path.join(data_label_path, path)\n",
    "        if os.path.isfile(path):\n",
    "            with open(path, 'r') as f:\n",
    "                box_coors = {}\n",
    "                ann_points = f.readlines()\n",
    "\n",
    "                for row in ann_points:\n",
    "                    row = row.split()\n",
    "                    lbl = row[8]\n",
    "                    \n",
    "                    if lbl[0:2] == 't1' or lbl[0:2] == 't2':\n",
    "                        lbl = 'L' + lbl[2]\n",
    "                    else:\n",
    "                        lbl = 'U' + lbl[2]\n",
    "                    \n",
    "                    coors = np.array([\n",
    "                                        [int(row[0]), int(row[1])],\n",
    "                                        [int(row[2]), int(row[3])],\n",
    "                                        [int(row[4]), int(row[5])],\n",
    "                                        [int(row[6]), int(row[7])]\n",
    "                                    ])\n",
    "                    \n",
    "                    vc1 = coors[1] - coors[0]\n",
    "                    vc2 = coors[2] - coors[1]\n",
    "                     \n",
    "                    if pil_img.size[0] > pil_img.size[1]:\n",
    "                        ax = np.array([1,0])\n",
    "                    else:\n",
    "                        ax = np.array([0,1])\n",
    "                        \n",
    "                    c1 = 180*np.arccos( np.dot(vc1,ax)/(np.linalg.norm(ax) * np.linalg.norm(vc1)) ) / math.pi\n",
    "                    c2 = 180*np.arccos( np.dot(vc2,ax)/(np.linalg.norm(ax) * np.linalg.norm(vc2)) ) / math.pi\n",
    "                    c1 = c1-90 if c1>=90 else c1\n",
    "                    c2 = c2-90 if c2>=90 else c2\n",
    "                    \n",
    "#                     boxwidth = np.linalg.norm(vc1)/img_diag if c1<=c2 else np.linalg.norm(vc2)/img_diag\n",
    "\n",
    "                    boxwidth = min(np.linalg.norm(vc1), np.linalg.norm(vc2)) / img_diag\n",
    "                    \n",
    "                    if (width_list:=teeth_widths.get(lbl, None)) is None:\n",
    "#                         if lbl in valid_lbls:\n",
    "                        teeth_widths[lbl] = [boxwidth]\n",
    "                    else:\n",
    "                        width_list.append(boxwidth)\n",
    "                        \n",
    "                        \n",
    "                    \n",
    "    return teeth_widths\n",
    "       \n",
    "                       \n",
    "train_teeth_widths =CreateTeethWidthData(train_label_32cls_path, train_img_path)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxplots for distribution of adjacent tooth distances\n",
    "# plot the boxplots for distribution of tooth widths\n",
    "# train_teeth_distances['L1_L2']\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "adj_dists = {}\n",
    "for i in range(3,8):\n",
    "    lbl = 'U' + str(i) + '_U' + str(i+1)\n",
    "    if (lst := train_teeth_distancesAndwidths.get(lbl, None)) is not None:\n",
    "        if adj_dists.get(lbl,None) is None:\n",
    "            adj_dists[lbl] = [d[0] for d in lst]\n",
    "        else:\n",
    "            adj_dists[lbl].extend([d[0] for d in lst])\n",
    "        \n",
    "    if (lst := test_teeth_distancesAndwidths.get(lbl, None)) is not None:\n",
    "        if adj_dists.get(lbl,None) is None:\n",
    "            adj_dists[lbl] = [d[0] for d in lst]\n",
    "        else:\n",
    "            adj_dists[lbl].extend([d[0] for d in lst])\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.boxplot(adj_dists.values(), labels=adj_dists.keys())\n",
    "ax.set_xlabel('Adjacent Tooth Pair (Upper Quadrants)')\n",
    "ax.set_ylabel('Normalized Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_dists = {}\n",
    "for i in range(3,8):\n",
    "    lbl = 'L' + str(i) + '_L' + str(i+1)\n",
    "    if (lst := train_teeth_distancesAndwidths.get(lbl, None)) is not None:\n",
    "        if adj_dists.get(lbl,None) is None:\n",
    "            adj_dists[lbl] = [d[0] for d in lst]\n",
    "        else:\n",
    "            adj_dists[lbl].extend([d[0] for d in lst])\n",
    "        \n",
    "    if (lst := test_teeth_distancesAndwidths.get(lbl, None)) is not None:\n",
    "        if adj_dists.get(lbl,None) is None:\n",
    "            adj_dists[lbl] = [d[0] for d in lst]\n",
    "        else:\n",
    "            adj_dists[lbl].extend([d[0] for d in lst])\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.boxplot(adj_dists.values(), labels=adj_dists.keys())\n",
    "ax.set_xlabel('Adjacent Tooth Pair (Lower Quadrants)')\n",
    "ax.set_ylabel('Normalized Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_iou = {}\n",
    "for i in range(3,8):\n",
    "    lbl = 'L' + str(i) + '_L' + str(i+1)\n",
    "    if (lst := train_teeth_distancesAndwidths.get(lbl, None)) is not None:\n",
    "        if adj_iou.get(lbl,None) is None:\n",
    "            adj_iou[lbl] = [d[3] for d in lst]\n",
    "        else:\n",
    "            adj_iou[lbl].extend([d[3] for d in lst])\n",
    "        \n",
    "    if (lst := test_teeth_distancesAndwidths.get(lbl, None)) is not None:\n",
    "        if adj_iou.get(lbl,None) is None:\n",
    "            adj_iou[lbl] = [d[3] for d in lst]\n",
    "        else:\n",
    "            adj_iou[lbl].extend([d[3] for d in lst])\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.boxplot(adj_iou.values(), labels=adj_iou.keys())\n",
    "ax.set_xlabel('Adjacent Tooth Pair (Lower Quadrants)')\n",
    "ax.set_ylabel('IoU of Bounding Box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52aab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_iou = {}\n",
    "for i in range(3,8):\n",
    "    lbl = 'U' + str(i) + '_U' + str(i+1)\n",
    "    if (lst := train_teeth_distancesAndwidths.get(lbl, None)) is not None:\n",
    "        if adj_iou.get(lbl,None) is None:\n",
    "            adj_iou[lbl] = [d[3] for d in lst]\n",
    "        else:\n",
    "            adj_iou[lbl].extend([d[3] for d in lst])\n",
    "        \n",
    "    if (lst := test_teeth_distancesAndwidths.get(lbl, None)) is not None:\n",
    "        if adj_iou.get(lbl,None) is None:\n",
    "            adj_iou[lbl] = [d[3] for d in lst]\n",
    "        else:\n",
    "            adj_iou[lbl].extend([d[3] for d in lst])\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.boxplot(adj_iou.values(), labels=adj_iou.keys())\n",
    "ax.set_xlabel('Adjacent Tooth Pair (Lower Quadrants)')\n",
    "ax.set_ylabel('IoU of Bounding Box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8937a54b",
   "metadata": {},
   "source": [
    "### Define a function to fit a SVM/Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c451094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a SVM classifier. \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def FitDistancesClassifier(train_distance_set, test_distance_set, source_labels, retain_labels, model_name):   \n",
    "\n",
    "    y_train_labels = []\n",
    "    X_train = []\n",
    "\n",
    "    y_test_labels = []\n",
    "    X_test = []\n",
    "\n",
    "    print('-----------------------------------------------------------')\n",
    "    print(f'Fit classifier for {source_labels}')\n",
    "    for lb in source_labels:\n",
    "\n",
    "        y_lb = lb if lb in retain_labels else 'OTHERS'\n",
    "\n",
    "        if (lst := train_distance_set.get(lb,None)) is not None:\n",
    "            y_train_labels.extend([y_lb for i in range(len(lst))])\n",
    "            X_train.extend(lst)\n",
    "        else:\n",
    "            print(f'{lb} is not found in training set')\n",
    "\n",
    "        if (lst := test_distance_set.get(lb,None)) is not None:\n",
    "            y_test_labels.extend([y_lb for i in range(len(lst))])\n",
    "            X_test.extend(lst)\n",
    "        else:\n",
    "            print(f'{lb} is not found in test set')\n",
    "            \n",
    "            \n",
    "    \n",
    "    if len(X_train) > 30:\n",
    "        print(f'Length of X_train is {len(X_train)}')\n",
    "        \n",
    "        if len(np.array(X_train).shape) == 1:\n",
    "            X_train = np.array(X_train).reshape(-1,1)\n",
    "            X_test = np.array(X_test).reshape(-1,1)\n",
    "\n",
    "        class_le = LabelEncoder()\n",
    "        y_train = class_le.fit_transform(y_train_labels)\n",
    "        y_test = class_le.fit_transform(y_test_labels)\n",
    "\n",
    "        # class_le.transform(['L5_L7', 'L3_L6'])\n",
    "        # class_le.inverse_transform([3,4])\n",
    "        \n",
    "        if model_name == 'SVM':\n",
    "            classifier = svm.SVC(probability=True, class_weight='balanced', random_state=721)\n",
    "        elif model_name == 'RandomForest':\n",
    "            classifier = RandomForestClassifier(class_weight='balanced', random_state=721)\n",
    "       \n",
    "        classifier.fit(X_train, y_train)\n",
    "       \n",
    "        \n",
    "        predicted = classifier.predict(X_test)\n",
    "        \n",
    "        predicted_prob = classifier.predict_proba(X_test)\n",
    "      \n",
    "        ap_scores = average_precision_score(y_test, predicted_prob, average='weighted')\n",
    "        \n",
    "\n",
    "        return classifier, class_le, metrics.classification_report(y_test, predicted), ap_scores\n",
    "    else:\n",
    "        print(f'*WARNING: Length of X_train is {len(X_train)}. Failed to fit due to insufficient of training data.')\n",
    "        return None, None, None\n",
    "    \n",
    "        \n",
    "def PlotToothDistanceDistribution(tooth_distance_set, source_labels, retain_labels, plot_title):   \n",
    "\n",
    "    y_labels = []\n",
    "    X = []\n",
    "\n",
    "    for lb in source_labels:\n",
    "\n",
    "        y_lb = lb if lb in retain_labels else 'OTHERS'\n",
    "\n",
    "        if (lst := tooth_distance_set.get(lb,None)) is not None:\n",
    "            y_labels.extend([y_lb for i in range(len(lst))])\n",
    "            X.extend(lst)\n",
    "                  \n",
    "    \n",
    "        if len(np.array(X).shape) == 1:\n",
    "            X = np.array(X).reshape(-1,1)\n",
    "           \n",
    "        class_le = LabelEncoder()\n",
    "        Y = class_le.fit_transform(y_labels)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    cmap = ListedColormap(sns.color_palette(as_cmap=True))\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    x = [feature[0] for feature in X]\n",
    "    y = [feature[1] for feature in X]\n",
    "    z = [feature[2] for feature in X]\n",
    "\n",
    "    sc = ax.scatter(x, y, z, s=3, c=Y, marker='o', cmap=cmap, alpha=1)\n",
    "\n",
    "    ax.set_xlabel(\"Tooth distance\")\n",
    "    ax.set_ylabel(\"i-th Tooth width\")\n",
    "    ax.set_zlabel(\"j-th Tooth width\")\n",
    "    ax.set_title(plot_title)\n",
    "\n",
    "#     plt.legend(handles=*sc.legend_elements(), labels=class_le.classes_, bbox_to_anchor=(1.05, 1), loc=\"upper right\")\n",
    "    handles, labels=sc.legend_elements()\n",
    "    labels = class_le.classes_\n",
    "    plt.legend(handles, labels,  loc=\"best\", fontsize=\"small\", ncols=2)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f9c03",
   "metadata": {},
   "source": [
    "### Fit classifiers for the teeth in the same quadrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8719b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls2_sameQ = {}\n",
    "# lblenc2_sameQ = {}\n",
    "# cls2_rpt_sameQ = {}\n",
    "\n",
    "\n",
    "# ### Fit classifiers for the teeth in the same quadrant\n",
    "def GenLabelPairs(isUpper,isNonMolar,isMolar):\n",
    "    source_labels = []\n",
    "    pf = 'L'\n",
    "    if isUpper:\n",
    "        pf = 'U'\n",
    "        \n",
    "    arange = []\n",
    "    if isNonMolar and isMolar:\n",
    "        arange = range(3,6)\n",
    "        brange = range(6,9)\n",
    "    elif not isNonMolar and isMolar:\n",
    "        arange = range(6,9)\n",
    "        brange = range(6,9)\n",
    "    elif isNonMolar and not isMolar:\n",
    "        arange = range(3,6)\n",
    "        brange = range(3,6)\n",
    "        \n",
    "    for j in arange:\n",
    "        for k in brange:\n",
    "            if k>j:\n",
    "                source_labels.append(pf+str(j)+'_'+pf+str(k))\n",
    "            \n",
    "    return source_labels\n",
    "\n",
    "\n",
    "cls_sameQ = {}\n",
    "lblenc_sameQ = {}\n",
    "cls_rpt_sameQ = {}\n",
    "ap_scores_sameQ = {}\n",
    "\n",
    "\n",
    "keys = ['U_MolarNonmolar', 'U_Molar', 'U_Nonmolar', \n",
    "       'L_MolarNonmolar', 'L_Molar', 'L_Nonmolar']\n",
    "switches = [[True, True, True], [True, False, True], [True, True, False],\n",
    "            [False, True, True], [False, False, True], [False, True, False]]\n",
    "\n",
    "\n",
    "train_set = {}\n",
    "for k,v in train_teeth_distancesAndwidths.items():\n",
    "    lst = [r[0:3] for r in v]\n",
    "    train_set[k]=lst\n",
    "    \n",
    "test_set = {}\n",
    "for k,v in test_teeth_distancesAndwidths.items():\n",
    "    lst = [r[0:3] for r in v]\n",
    "    test_set[k]=lst\n",
    "    \n",
    "\n",
    "for key, switch in zip(keys, switches):\n",
    "    source_labels = GenLabelPairs(isUpper=switch[0],isNonMolar=switch[1],isMolar=switch[2])\n",
    "    \n",
    "    if len(source_labels)>1:\n",
    "        cls_sameQ[key], lblenc_sameQ[key], cls_rpt_sameQ[key], ap_scores_sameQ[key] = FitDistancesClassifier(train_set, \n",
    "                                                                                test_set, \n",
    "                                                                                source_labels, \n",
    "                                                                                source_labels,\n",
    "                                                                                'SVM')\n",
    "\n",
    "\n",
    "\n",
    "        if cls_rpt_sameQ[key] is not None:       \n",
    "            print([str(ind) + \": \" + val for ind,val in enumerate(lblenc_sameQ[key].classes_)])\n",
    "\n",
    "            print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "                  % (cls_sameQ[key], cls_rpt_sameQ[key]))\n",
    "            \n",
    "            print(\"Average Precision score for classifier %s:\\n%s\\n\"\n",
    "                  % (cls_sameQ[key], ap_scores_sameQ[key]))\n",
    "    else:\n",
    "        cls_sameQ[key], lblenc_sameQ[key], cls_rpt_sameQ[key], ap_scores_sameQ[key] = None, None, None, None\n",
    "        print('---------------------------------------------------------')\n",
    "        print(f'{key} has only single class {source_labels}. No classifier is fitted.')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e07db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tooth pair distributions \n",
    "\n",
    "%matplotlib notebook\n",
    "  \n",
    "source_labels = ['U3_U4', 'U3_U5', 'U4_U5']\n",
    "PlotToothDistanceDistribution(train_set, source_labels, \n",
    "                              source_labels,\n",
    "                             \"Scatter Plot of Tooth Pairs in Upper Quadrants\")  \n",
    "     \n",
    "\n",
    "source_labels = ['L3_L4', 'L3_L5', 'L4_L5']\n",
    "PlotToothDistanceDistribution(train_set, source_labels, \n",
    "                              source_labels,\n",
    "                             \"Scatter Plot of Tooth Pairs in Lower Quadrants\")  \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa72879",
   "metadata": {},
   "source": [
    "### Fit classifiers for the teeth in the opposite quadrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fef6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier for teeth in opposite quadrants\n",
    "cls_oppositeQ = {}\n",
    "lblenc_oppositeQ = {}\n",
    "cls_rpt_oppositeQ = {}\n",
    "ap_scores_oppositeQ = {}\n",
    "\n",
    "source_labels = {}\n",
    "\n",
    "arange = range(3,9)\n",
    "for j in arange:\n",
    "\n",
    "    key = 'U' + str(j)\n",
    "    lst = ['U' + str(j) + '_L' + str(k) for k in arange]\n",
    "    source_labels[key] = lst\n",
    "    \n",
    "    key = 'L' + str(j)\n",
    "    lst = ['L' + str(j) + '_U' + str(k) for k in arange]\n",
    "    source_labels[key] = lst\n",
    "    \n",
    "    \n",
    "\n",
    "train_set = {}\n",
    "for k,v in train_teeth_distancesAndwidths.items():\n",
    "    lst = [r[0:3] for r in v]\n",
    "    train_set[k]=lst\n",
    "    \n",
    "test_set = {}\n",
    "for k,v in test_teeth_distancesAndwidths.items():\n",
    "    lst = [r[0:3] for r in v]\n",
    "    test_set[k]=lst\n",
    "    \n",
    "\n",
    "### Fit classifiers for the teeth in the opposite quadrant\n",
    "for key,lblst in source_labels.items():\n",
    "    src_lbls = lblst\n",
    "    retain_lbls = lblst[0]\n",
    "    \n",
    "    print(src_lbls) \n",
    "    cls_oppositeQ[key], lblenc_oppositeQ[key], cls_rpt_oppositeQ[key], ap_scores_oppositeQ[key] = FitDistancesClassifier(train_set, \n",
    "                                                                                test_set, \n",
    "                                                                                src_lbls, \n",
    "                                                                                src_lbls,\n",
    "                                                                                'SVM')\n",
    "                                                               \n",
    "    \n",
    "    if cls_rpt_oppositeQ[key] is not None:       \n",
    "        print([str(ind) + \": \" + val for ind,val in enumerate(lblenc_oppositeQ[key].classes_)])\n",
    "        \n",
    "        print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "              % (cls_oppositeQ[key], cls_rpt_oppositeQ[key]))\n",
    "        \n",
    "        print(\"Average Precision score for classifier %s:\\n%s\\n\"\n",
    "                  % (cls_oppositeQ[key], ap_scores_oppositeQ[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tooth distributions \n",
    "\n",
    "%matplotlib notebook\n",
    "  \n",
    "    \n",
    "source_labels = ['L5_U3', 'L5_U4', 'L5_U5', 'L5_U6', 'L5_U7', 'L5_U8']\n",
    "PlotToothDistanceDistribution(train_set, source_labels, \n",
    "                              source_labels,\n",
    "                             \"Scatter Plot of Tooth Pairs in Opposite Quadrants\")  \n",
    "\n",
    "source_labels = ['L6_U3', 'L6_U4', 'L6_U5', 'L6_U6', 'L6_U7', 'L6_U8']\n",
    "\n",
    "PlotToothDistanceDistribution(train_set, source_labels, \n",
    "                              source_labels,\n",
    "                             \"Scatter Plot of Tooth Pairs in Opposite Quadrants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adefed41",
   "metadata": {},
   "source": [
    "# Stage 4 - Inference by combining Stage 1 to Stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import collections\n",
    "import sys\n",
    "\n",
    "stage2_inference_label_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/6XX_4cls_scratch_yolo5m_detect_conf0p6_iou0p45_/labels'\n",
    "inference_img_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/6XX_4cls_scratch_yolo5m_detect_conf0p6_iou0p45_'\n",
    "stage3_inference_label_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage3/stage3outputlabels'\n",
    "\n",
    "shutil.rmtree(stage3_inference_label_path)\n",
    "\n",
    "detect_classes = ['U_molar', 'U_nonmolar', 'L_molar', 'L_nonmolar']\n",
    "\n",
    "valid_lbls = { 'UpperQ': ['U1', 'U2', 'U3', 'U4', 'U5', 'U6', 'U7', 'U8'],\n",
    "               'LowerQ': ['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8']\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d72f19",
   "metadata": {},
   "source": [
    "#### Define functions and perform steps by steps decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e79ec5",
   "metadata": {
    "code_folding": [
     18
    ]
   },
   "outputs": [],
   "source": [
    "IoU_THRESHOLD = 0.5\n",
    "\n",
    "def sort_coordinates(list_of_xy_coords, is_clockwise):\n",
    "    cx, cy = list_of_xy_coords.mean(0)\n",
    "    x, y = list_of_xy_coords.T\n",
    "    angles = np.arctan2(x-cx, y-cy)\n",
    "    indices = np.argsort(-1*angles) if is_clockwise else np.argsort(angles)\n",
    "    \n",
    "    return list_of_xy_coords[indices]\n",
    "\n",
    "    \n",
    "def check_overlapped_teeth_box(teeth):\n",
    "\n",
    "    for i in range(0, len(teeth)):\n",
    "        for j in range(i+1, len(teeth)):\n",
    "            r1 = Polygon(teeth[i]['corners'])\n",
    "            r2 = Polygon(teeth[j]['corners'])\n",
    "            \n",
    "            if r1.intersection(r2).area / r1.union(r2).area >= IoU_THRESHOLD:\n",
    "                # IoU above threshold. Compare the object confidence \n",
    "                teeth[j]['is_redundant'] = (teeth[i]['conf'] >= teeth[j]['conf']) or teeth[j]['is_redundant']\n",
    "                teeth[i]['is_redundant'] = (teeth[i]['conf'] < teeth[j]['conf']) or teeth[i]['is_redundant']\n",
    "\n",
    "\n",
    "\n",
    "# To identify the nonmolar and molar pair with shortest distance\n",
    "def determine_nonmolar_molar(teeth, tooth_register, is_upperQ):\n",
    "   \n",
    "    detect_count = 0\n",
    "\n",
    "    quad_class = []\n",
    "    if is_upperQ:\n",
    "        quad_class.append('U_nonmolar')\n",
    "        quad_class.append('U_molar')\n",
    "        quad_class.append('U_MolarNonmolar')\n",
    "    else:\n",
    "        quad_class.append('L_nonmolar')\n",
    "        quad_class.append('L_molar')\n",
    "        quad_class.append('L_MolarNonmolar')\n",
    "        \n",
    "    mindist = sys.float_info.max\n",
    "    \n",
    "    # find the minimum distance between a molar and nonmolar\n",
    "    for x in teeth:\n",
    "        if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] :\n",
    "            for y in teeth:\n",
    "                if y['molar_nonmolar'] == quad_class[1] and not y['is_redundant'] and x is not y:  \n",
    "                    dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                    mindist = dist if dist < mindist else mindist\n",
    "    \n",
    "    \n",
    "    for x in teeth:\n",
    "        if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] :\n",
    "            for y in teeth:\n",
    "                if y['molar_nonmolar'] == quad_class[1] and not y['is_redundant'] and x is not y:  \n",
    "                    dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                    if dist == mindist:\n",
    "                        # x, y is the closest nonmolar  and molar teeth. Use the classifier to predict it.\n",
    "                        \n",
    "                        wx1 = np.linalg.norm(x['corners'][0] - x['corners'][1])\n",
    "                        wx2 = np.linalg.norm(x['corners'][1] - x['corners'][2])\n",
    "                        wx = min(wx1,wx2)/x['img_diag']\n",
    "                        \n",
    "                        wy1 = np.linalg.norm(y['corners'][0] - y['corners'][1])\n",
    "                        wy2 = np.linalg.norm(y['corners'][1] - y['corners'][2])\n",
    "                        wy = min(wy1,wy2)/y['img_diag']\n",
    "                        \n",
    "                        # img_diag should be the same in x and y as they in the same image\n",
    "                        dist = dist/x['img_diag']\n",
    "                        \n",
    "                     \n",
    "                        \n",
    "                        # the widths and box distance should be normalized before feed to classifier\n",
    "                        output_prob = cls_sameQ[quad_class[2]].predict_proba(np.array([[dist, wx, wy]]))\n",
    "                        output_label = lblenc_sameQ[quad_class[2]].classes_[np.argmax(output_prob)]\n",
    "                        tootha, toothb = output_label.split('_')\n",
    "                        x['tooth_number_pred'].append(tootha)\n",
    "                        x['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                        y['tooth_number_pred'].append(toothb)\n",
    "                        y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                        \n",
    "                        tooth_register[tootha] = 'FOUND' \n",
    "                        tooth_register[toothb] = 'FOUND'\n",
    "                        detect_count += 1\n",
    "                        \n",
    "    return detect_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# To identify the molar pairs\n",
    "def determine_molar(teeth, tooth_register, is_upperQ):\n",
    "   \n",
    "    detect_count = 0\n",
    "\n",
    "    quad_class = []\n",
    "    if is_upperQ:\n",
    "        quad_class.append('U_molar')\n",
    "        quad_class.append('U_molar')\n",
    "        quad_class.append('U_Molar')\n",
    "    else:\n",
    "        quad_class.append('L_molar')\n",
    "        quad_class.append('L_molar')\n",
    "        quad_class.append('L_Molar')\n",
    "        \n",
    "    molar_cnt = 0\n",
    "    for x in teeth:\n",
    "        if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant']:\n",
    "            molar_cnt +=1\n",
    "            \n",
    "    if molar_cnt<2:\n",
    "        print(f'There is only {molar_cnt} teeth. No need to predict molar pairs!')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # find the minimum distance between a molar pair\n",
    "    is_already_determined_molar = False\n",
    "    \n",
    "    for x in teeth:\n",
    "        if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] :\n",
    "            if len(x['tooth_number_pred'])>0:\n",
    "                is_already_determined_molar = True\n",
    "                    \n",
    "                    \n",
    "    if not is_already_determined_molar:\n",
    "        # No molar tooth is identified before, pick the closes distance pair to predict\n",
    "        \n",
    "        mindist = sys.float_info.max\n",
    "        for x in teeth:\n",
    "            if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] :\n",
    "                for y in teeth:\n",
    "                    if y['molar_nonmolar'] == quad_class[1] and not y['is_redundant'] and x is not y:  \n",
    "                        dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                        mindist = dist if dist < mindist else mindist\n",
    "\n",
    "\n",
    "        for x in teeth:\n",
    "            if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] :\n",
    "                for y in teeth:\n",
    "                    if y['molar_nonmolar'] == quad_class[1] and not y['is_redundant'] and x is not y:  \n",
    "                        dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                        if dist == mindist:\n",
    "                            # x, y is the closest nonmolar  and molar teeth. Use the classifier to predict it.\n",
    "\n",
    "                            wx1 = np.linalg.norm(x['corners'][0] - x['corners'][1])\n",
    "                            wx2 = np.linalg.norm(x['corners'][1] - x['corners'][2])\n",
    "                            wx = min(wx1,wx2)/x['img_diag']\n",
    "\n",
    "                            wy1 = np.linalg.norm(y['corners'][0] - y['corners'][1])\n",
    "                            wy2 = np.linalg.norm(y['corners'][1] - y['corners'][2])\n",
    "                            wy = min(wy1,wy2)/y['img_diag']\n",
    "\n",
    "                            # img_diag should be the same in x and y as they in the same image\n",
    "                            dist = dist/x['img_diag']\n",
    "                            \n",
    "                      \n",
    "                            # the widths and box distance should be normalized before feed to classifier\n",
    "                            output_prob = cls_sameQ[quad_class[2]].predict_proba(np.array([[dist, wx, wy]]))\n",
    "                            output_label = lblenc_sameQ[quad_class[2]].classes_[np.argmax(output_prob)]\n",
    "                            tootha, toothb = output_label.split('_')\n",
    "                            x['tooth_number_pred'].append(tootha)\n",
    "                            x['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                            y['tooth_number_pred'].append(toothb)\n",
    "                            y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "\n",
    "                            tooth_register[tootha] = 'FOUND' \n",
    "                            tooth_register[toothb] = 'FOUND'\n",
    "                            detect_count += 1\n",
    "                            \n",
    "    \n",
    "    # a molar tooth is identified before, predict from the identified one\n",
    "    is_all_molar_determined = False\n",
    "    \n",
    "    while not is_all_molar_determined:\n",
    "        \n",
    "        mindist = sys.float_info.max\n",
    "        \n",
    "        for x in teeth:\n",
    "            if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] and len(x['tooth_number_pred'])>0:\n",
    "                for y in teeth:\n",
    "                    if y['molar_nonmolar'] == quad_class[1] and not y['is_redundant'] and x is not y and \\\n",
    "                        len(y['tooth_number_pred'])==0:  \n",
    "                        dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                        mindist = dist if dist < mindist else mindist\n",
    "\n",
    "\n",
    "        for x in teeth:\n",
    "            if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] and len(x['tooth_number_pred'])>0:\n",
    "                for y in teeth:\n",
    "                    if y['molar_nonmolar'] == quad_class[1] and not y['is_redundant'] and x is not y and \\\n",
    "                        len(y['tooth_number_pred'])==0:  \n",
    "\n",
    "                        dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                        if dist == mindist:\n",
    "                            # x, y is the closest  molar teeth. Use the classifier to predict it.\n",
    "\n",
    "                            wx1 = np.linalg.norm(x['corners'][0] - x['corners'][1])\n",
    "                            wx2 = np.linalg.norm(x['corners'][1] - x['corners'][2])\n",
    "                            wx = min(wx1,wx2)/x['img_diag']\n",
    "\n",
    "                            wy1 = np.linalg.norm(y['corners'][0] - y['corners'][1])\n",
    "                            wy2 = np.linalg.norm(y['corners'][1] - y['corners'][2])\n",
    "                            wy = min(wy1,wy2)/y['img_diag']\n",
    "\n",
    "                            # img_diag should be the same in x and y as they in the same image\n",
    "                            dist = dist/x['img_diag']\n",
    "                            \n",
    "                        \n",
    "\n",
    "                            # the widths and box distance should be normalized before feed to classifier\n",
    "                            output_prob = cls_sameQ[quad_class[2]].predict_proba(np.array([[dist, wx, wy]])) \n",
    "                            #output_label = lblenc_sameQ[quad_class[2]].classes_[np.argmax(output_prob)]\n",
    "                            #tootha, toothb = output_label.split('_')\n",
    "                            \n",
    "                            \n",
    "                            # To prevent from duplicate prediction\n",
    "                            try_prob = output_prob.copy()\n",
    "                            is_found = False\n",
    "                            while not is_found:\n",
    "                                output_label = lblenc_sameQ[quad_class[2]].classes_[np.argmax(try_prob)]\n",
    "                                tootha, toothb = output_label.split('_')\n",
    "                             \n",
    "                                if (tooth_register[tootha]=='FOUND' and tooth_register[toothb]=='FOUND') or \\\n",
    "                                    (tooth_register[tootha]!='FOUND' and tooth_register[toothb]!='FOUND') :\n",
    "                                    # both teeth had been identified or both not found, use the lower conf predictions\n",
    "                                    try_prob[0][np.argmax(try_prob)] = -1\n",
    "                                else:\n",
    "                                    is_found=True\n",
    "                                \n",
    "                                # quit the loop if trying all \n",
    "                                if try_prob[0][np.argmax(try_prob)] == -1:\n",
    "                                    is_found = True\n",
    "                            \n",
    "\n",
    "                            if x['tooth_number_pred'][-1]==tootha:\n",
    "                                y['tooth_number_pred'].append(toothb)\n",
    "                                y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                tooth_register[toothb]='FOUND' \n",
    "                                detect_count += 1\n",
    "                            elif x['tooth_number_pred'][-1]==toothb:\n",
    "                                y['tooth_number_pred'].append(tootha)\n",
    "                                y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                tooth_register[tootha]='FOUND' \n",
    "                                detect_count += 1\n",
    "                            else:\n",
    "                                xlbl = x['tooth_number_pred'][-1]\n",
    "                                print(f'*****WARNING: Previous stage determined {xlbl}, but now have ({tootha}, {toothb})')\n",
    "                                \n",
    "                                x['tooth_number_pred'].append(tootha)\n",
    "                                x['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                \n",
    "                                x['tooth_number_pred'].append(toothb)\n",
    "                                x['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                \n",
    "                                y['tooth_number_pred'].append(tootha)\n",
    "                                y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                \n",
    "                                y['tooth_number_pred'].append(toothb)\n",
    "                                y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                \n",
    "                                tooth_register[tootha]='FOUND' \n",
    "                                tooth_register[toothb]='FOUND' \n",
    "                                detect_count += 1\n",
    "                                \n",
    "                                \n",
    "        is_all_molar_determined = True\n",
    "        for x in teeth:\n",
    "            if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] and len(x['tooth_number_pred'])==0:\n",
    "                is_all_molar_determined = False\n",
    "            \n",
    "    return detect_count\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# To identify the nonmolar pairs\n",
    "def determine_nonmolar(teeth, tooth_register, is_upperQ):\n",
    "   \n",
    "    detect_count = 0\n",
    "\n",
    "    quad_class = []\n",
    "    if is_upperQ:\n",
    "        quad_class.append('U_nonmolar')\n",
    "        quad_class.append('U_nonmolar')\n",
    "        quad_class.append('U_Nonmolar')\n",
    "    else:\n",
    "        quad_class.append('L_nonmolar')\n",
    "        quad_class.append('L_nonmolar')\n",
    "        quad_class.append('L_Nonmolar')\n",
    "        \n",
    "    nonmolar_cnt = 0\n",
    "    for x in teeth:\n",
    "        if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant']:\n",
    "            nonmolar_cnt +=1\n",
    "            \n",
    "    if nonmolar_cnt<2:\n",
    "        print(f'There is only {nonmolar_cnt} teeth. No need to predict nonmolar pairs!')\n",
    "        return \n",
    "    \n",
    "    \n",
    "    # find the minimum distance between a molar pair\n",
    "    is_already_determined_nonmolar = False\n",
    "    \n",
    "    for x in teeth:\n",
    "        if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] :\n",
    "            if len(x['tooth_number_pred'])>0:\n",
    "                is_already_determined_nonmolar = True\n",
    "                    \n",
    "                    \n",
    "    if not is_already_determined_nonmolar:\n",
    "        # No nonmolar tooth is identified before, pick the closes distance pair to predict\n",
    "        \n",
    "        mindist = sys.float_info.max\n",
    "        for x in teeth:\n",
    "            if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] :\n",
    "                for y in teeth:\n",
    "                    if y['molar_nonmolar'] == quad_class[1] and not y['is_redundant'] and x is not y:  \n",
    "                        dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                        mindist = dist if dist < mindist else mindist\n",
    "\n",
    "\n",
    "        for x in teeth:\n",
    "            if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] :\n",
    "                for y in teeth:\n",
    "                    if y['molar_nonmolar'] == quad_class[1] and not y['is_redundant'] and x is not y:  \n",
    "                        dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                        if dist == mindist:\n",
    "                            # x, y is the closest nonmolar   teeth. Use the classifier to predict it.\n",
    "\n",
    "                            wx1 = np.linalg.norm(x['corners'][0] - x['corners'][1])\n",
    "                            wx2 = np.linalg.norm(x['corners'][1] - x['corners'][2])\n",
    "                            wx = min(wx1,wx2)/x['img_diag']\n",
    "\n",
    "                            wy1 = np.linalg.norm(y['corners'][0] - y['corners'][1])\n",
    "                            wy2 = np.linalg.norm(y['corners'][1] - y['corners'][2])\n",
    "                            wy = min(wy1,wy2)/y['img_diag']\n",
    "\n",
    "                            # img_diag should be the same in x and y as they in the same image\n",
    "                            # the widths and box distance should be normalized before feed to classifier\n",
    "                            dist = dist/x['img_diag']\n",
    "                            \n",
    "                       \n",
    "                            if cls_sameQ[quad_class[2]] != None:\n",
    "                                output_prob = cls_sameQ[quad_class[2]].predict_proba(np.array([[dist, wx, wy]]))\n",
    "                                output_label = lblenc_sameQ[quad_class[2]].classes_[np.argmax(output_prob)]\n",
    "                                \n",
    "                            else:\n",
    "                                # a None classifier is due to insufficient t3 data to fit a classifier, only a workaround here.\n",
    "                                output_prob = 1\n",
    "                                if is_upperQ:\n",
    "                                    output_label = 'U4_U5'\n",
    "                                else:\n",
    "                                    output_label = 'L4_L5'\n",
    "                                \n",
    "                            tootha, toothb = output_label.split('_')\n",
    "                            x['tooth_number_pred'].append(tootha)\n",
    "                            x['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                            y['tooth_number_pred'].append(toothb)\n",
    "                            y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "\n",
    "                            tooth_register[tootha] = 'FOUND' \n",
    "                            tooth_register[toothb] = 'FOUND'\n",
    "                            detect_count += 1\n",
    "                            \n",
    "                                \n",
    "                            \n",
    "    \n",
    "    # a nonmolar tooth is identified before, predict from the identified one\n",
    "    is_all_nonmolar_determined = False\n",
    "    \n",
    "    while not is_all_nonmolar_determined:\n",
    "        \n",
    "        mindist = sys.float_info.max\n",
    "        \n",
    "        for x in teeth:\n",
    "            if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] and len(x['tooth_number_pred'])>0:\n",
    "                for y in teeth:\n",
    "                    if y['molar_nonmolar'] == quad_class[1] and not y['is_redundant'] and x is not y and \\\n",
    "                        len(y['tooth_number_pred'])==0:  \n",
    "                        dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                        mindist = dist if dist < mindist else mindist\n",
    "\n",
    "\n",
    "        for x in teeth:\n",
    "            if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] and len(x['tooth_number_pred'])>0:\n",
    "                for y in teeth:\n",
    "                    if y['molar_nonmolar'] == quad_class[1] and not y['is_redundant'] and x is not y and \\\n",
    "                        len(y['tooth_number_pred'])==0:  \n",
    "\n",
    "                        dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                        if dist == mindist:\n",
    "                            # x, y is the closest nonmolar  and molar teeth. Use the classifier to predict it.\n",
    "\n",
    "                            wx1 = np.linalg.norm(x['corners'][0] - x['corners'][1])\n",
    "                            wx2 = np.linalg.norm(x['corners'][1] - x['corners'][2])\n",
    "                            wx = min(wx1,wx2)/x['img_diag']\n",
    "\n",
    "                            wy1 = np.linalg.norm(y['corners'][0] - y['corners'][1])\n",
    "                            wy2 = np.linalg.norm(y['corners'][1] - y['corners'][2])\n",
    "                            wy = min(wy1,wy2)/y['img_diag']\n",
    "\n",
    "                            # img_diag should be the same in x and y as they in the same image\n",
    "                            dist = dist/x['img_diag']\n",
    "                            \n",
    "\n",
    "\n",
    "                            # the widths and box distance should be normalized before feed to classifier\n",
    "                            if cls_sameQ[quad_class[2]] != None:\n",
    "                                output_prob = cls_sameQ[quad_class[2]].predict_proba(np.array([[dist, wx, wy]]))\n",
    "                                #output_label = lblenc_sameQ[quad_class[2]].classes_[np.argmax(output_prob)]\n",
    "                                \n",
    "                                # To prevent from duplicate prediction\n",
    "                                try_prob = output_prob.copy()\n",
    "                                is_found = False\n",
    "                                while not is_found:\n",
    "                                    output_label = lblenc_sameQ[quad_class[2]].classes_[np.argmax(try_prob)]\n",
    "                                    tootha, toothb = output_label.split('_')\n",
    "\n",
    "                                    if (tooth_register[tootha]=='FOUND' and tooth_register[toothb]=='FOUND') or \\\n",
    "                                        (tooth_register[tootha]!='FOUND' and tooth_register[toothb]!='FOUND') :\n",
    "                                        # both teeth had been identified or both not found, use the lower conf predictions\n",
    "                                        try_prob[0][np.argmax(try_prob)] = -1\n",
    "                                    else:\n",
    "                                        is_found=True\n",
    "\n",
    "                                    # quit the loop if trying all \n",
    "                                    if try_prob[0][np.argmax(try_prob)] == -1:\n",
    "                                        is_found = True\n",
    "                                \n",
    "                            else:\n",
    "                                # a None classifier is due to insufficient t3 data to fit a classifier, only a workaround here.\n",
    "                                output_prob = 1\n",
    "                                if is_upperQ:\n",
    "                                    output_label = 'U4_U5'\n",
    "                                else:\n",
    "                                    output_label = 'L4_L5'\n",
    "                                    \n",
    "                            \n",
    "                            \n",
    "                            tootha, toothb = output_label.split('_')\n",
    "\n",
    "                            if x['tooth_number_pred'][-1]==tootha:\n",
    "                                y['tooth_number_pred'].append(toothb)\n",
    "                                y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                tooth_register[toothb]='FOUND' \n",
    "                                detect_count += 1\n",
    "                            elif x['tooth_number_pred'][-1]==toothb:\n",
    "                                y['tooth_number_pred'].append(tootha) \n",
    "                                y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                tooth_register[tootha]='FOUND' \n",
    "                                detect_count += 1\n",
    "                            else:\n",
    "                                xlbl = x['tooth_number_pred'][-1]\n",
    "                                print(f'*****WARNING: Previous stage determined {xlbl}, but now have ({tootha}, {toothb})')\n",
    "                                \n",
    "                                x['tooth_number_pred'].append(tootha)\n",
    "                                x['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                \n",
    "                                x['tooth_number_pred'].append(toothb)\n",
    "                                x['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                \n",
    "                                y['tooth_number_pred'].append(tootha)\n",
    "                                y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                \n",
    "                                y['tooth_number_pred'].append(toothb)\n",
    "                                y['tooth_number_pred_conf'].append(str(round(np.max(output_prob),2)))\n",
    "                                \n",
    "                                tooth_register[tootha]='FOUND' \n",
    "                                tooth_register[toothb]='FOUND' \n",
    "                                detect_count += 1\n",
    "                                \n",
    "                                \n",
    "        is_all_nonmolar_determined = True\n",
    "        for x in teeth:\n",
    "            if x['molar_nonmolar'] == quad_class[0] and not x['is_redundant'] and len(x['tooth_number_pred'])==0:\n",
    "                is_all_nonmolar_determined = False\n",
    "            \n",
    "    return detect_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# To identify the nonmolar pairs\n",
    "def determine_opposite_quad(teeth, tooth_register, is_upperQ):\n",
    "   \n",
    "    detect_count = 0\n",
    "    \n",
    "    quad_class = []\n",
    "    if is_upperQ:\n",
    "        quad_class.append('U_nonmolar')\n",
    "        quad_class.append('U_molar')\n",
    "        quad_class.append('L_nonmolar')\n",
    "        quad_class.append('L_molar')\n",
    "    else:\n",
    "        quad_class.append('L_nonmolar')\n",
    "        quad_class.append('L_molar')\n",
    "        quad_class.append('U_nonmolar')\n",
    "        quad_class.append('U_molar')\n",
    "\n",
    "    mindist = sys.float_info.max\n",
    "    for x in teeth:\n",
    "        \n",
    "        mindist = sys.float_info.max\n",
    "        \n",
    "        if (x['molar_nonmolar'] == quad_class[0] or x['molar_nonmolar'] == quad_class[1]) and not x['is_redundant'] :\n",
    "            for y in teeth:\n",
    "                if (y['molar_nonmolar'] == quad_class[2] or y['molar_nonmolar'] == quad_class[3]) and not y['is_redundant'] \\\n",
    "                    and len(y['tooth_number_pred'])>0:\n",
    "                    \n",
    "                    dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                    mindist = dist if dist < mindist else mindist\n",
    "                    \n",
    "                    \n",
    "            for y in teeth:\n",
    "                if (y['molar_nonmolar'] == quad_class[2] or y['molar_nonmolar'] == quad_class[3]) and not y['is_redundant'] \\\n",
    "                    and len(y['tooth_number_pred'])>0:\n",
    "                    \n",
    "                    dist = np.linalg.norm(x['center'] - y['center'])\n",
    "                    \n",
    "                    if dist == mindist:\n",
    "                         # x, y is the closest oppositve quad teeth. Use the classifier to predict it.\n",
    "\n",
    "                        wx1 = np.linalg.norm(x['corners'][0] - x['corners'][1])\n",
    "                        wx2 = np.linalg.norm(x['corners'][1] - x['corners'][2])\n",
    "                        wx = min(wx1,wx2)/x['img_diag']\n",
    "\n",
    "                        wy1 = np.linalg.norm(y['corners'][0] - y['corners'][1])\n",
    "                        wy2 = np.linalg.norm(y['corners'][1] - y['corners'][2])\n",
    "                        wy = min(wy1,wy2)/y['img_diag']\n",
    "\n",
    "                        # img_diag should be the same in x and y as they in the same image\n",
    "                        dist = dist/x['img_diag']\n",
    "                        \n",
    "\n",
    "\n",
    "                        y_tooth_lbl = y['tooth_number_pred'][np.argmax(y['tooth_number_pred_conf'])]\n",
    "                        \n",
    "                        output_prob = cls_oppositeQ[y_tooth_lbl].predict_proba(np.array([[dist, wx, wy]]))\n",
    "                        output_label = lblenc_oppositeQ[y_tooth_lbl].classes_[np.argmax(output_prob)]\n",
    "                        \n",
    "                        tootha, toothb = output_label.split('_')\n",
    "\n",
    "                        x['tooth_number_pred'].append(toothb)\n",
    "                        x['tooth_number_pred_conf'].append('9999')\n",
    "\n",
    "                        tooth_register[toothb]='FOUND' \n",
    "                       \n",
    "                        detect_count += 1\n",
    "\n",
    "    return detect_count\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "if not os.path.exists(stage3_inference_label_path):\n",
    "    os.makedirs(stage3_inference_label_path)\n",
    "    \n",
    "# get the inference label\n",
    "for path in os.listdir(stage2_inference_label_path):\n",
    "    \n",
    "    pf, sf = path.split('.')\n",
    "    pil_img = Image.open(os.path.join(inference_img_path, pf + '.png'))\n",
    "    \n",
    "    img_diag = (pil_img.size[0]**2 + pil_img.size[1]**2)**0.5\n",
    " \n",
    "    path = os.path.join(stage2_inference_label_path, path)    \n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'r') as f:\n",
    "            \n",
    "            infered_boxes = []\n",
    "            lines = f.readlines()\n",
    "            for row in lines:\n",
    "                box  = {}\n",
    "                row = row.split()\n",
    "                box['molar_nonmolar_code'] = row[0]\n",
    "                box['molar_nonmolar'] = detect_classes[int(row[0])]\n",
    "                box['conf'] = float(row[-1])\n",
    "            \n",
    "                corners = np.array([[float(row[1]), float(row[2])], \n",
    "                            [float(row[3]), float(row[4])],\n",
    "                            [float(row[5]), float(row[6])],\n",
    "                            [float(row[7]), float(row[8])]])\n",
    "\n",
    "                \n",
    "                corners = sort_coordinates(corners,True)\n",
    "                box['corners'] = corners\n",
    "                \n",
    "                # center coordinates \n",
    "                box['center'] = 0.5*(corners[0] + corners[2])\n",
    "                \n",
    "                box['img_diag'] = img_diag\n",
    "                \n",
    "                \n",
    "                # a flag to indicate whether the box is overlapped with IoU > threshold. If True, it will be ignored.\n",
    "                box['is_redundant'] = False\n",
    "                                   \n",
    "                box['tooth_number_pred'] = []\n",
    "                box['tooth_number_pred_conf'] = []\n",
    "                 \n",
    "                infered_boxes.append(box)\n",
    "               \n",
    "            # a register to hold the detected result of each image. UNK=unknown, FOUND, MISSING\n",
    "            infered_tooth_register = {}\n",
    "            for lbl in valid_lbls['UpperQ']:\n",
    "                infered_tooth_register[lbl] = 'UNK'\n",
    "            for lbl in valid_lbls['LowerQ']:\n",
    "                infered_tooth_register[lbl] = 'UNK'\n",
    "            \n",
    "            check_overlapped_teeth_box(infered_boxes)\n",
    "           \n",
    "            # First step is to determine closest {nonmolar, molar} pair  \n",
    "            count_upper_nomolar_molar = determine_nonmolar_molar(teeth=infered_boxes, tooth_register=infered_tooth_register, is_upperQ=True)\n",
    "            print(f'{pf} has {count_upper_nomolar_molar} Upper (Nonmolar,Molar) detection!')\n",
    "                \n",
    "            count_lower_nomolar_molar = determine_nonmolar_molar(teeth=infered_boxes, tooth_register=infered_tooth_register, is_upperQ=False)\n",
    "            print(f'{pf} has {count_lower_nomolar_molar} Lower (Nonmolar,Molar) detection!')\n",
    "                \n",
    "            \n",
    "            # Second step is to determine molar pairs, also given a molar has been found in first step\n",
    "            count = determine_molar(teeth=infered_boxes, tooth_register=infered_tooth_register, is_upperQ=True)\n",
    "            print(f'{pf} has {count} Upper (Molar,Molar) detection!')\n",
    "                \n",
    "            count = determine_molar(teeth=infered_boxes, tooth_register=infered_tooth_register, is_upperQ=False)\n",
    "            print(f'{pf} has {count} Lower (Molar,Molar) detection!')\n",
    "            \n",
    "            \n",
    "            # Third step is to determine nonmolar pairs, also given a nonmolar has been found in first step\n",
    "            count = determine_nonmolar(teeth=infered_boxes, tooth_register=infered_tooth_register, is_upperQ=True)\n",
    "            print(f'{pf} has {count} Upper (Nonmolar,Nonmolar) detection!')\n",
    "                \n",
    "            count = determine_nonmolar(teeth=infered_boxes, tooth_register=infered_tooth_register, is_upperQ=False)\n",
    "            print(f'{pf} has {count} Lower (Nonmolar,Nonmolar) detection!')\n",
    "            \n",
    "            \n",
    "            # Finally, if no nonmolar and molar pair identified in the same quad, then we need to opposite quad for prediction\n",
    "            # opposite quad prediction is overriding as it is more accurate\n",
    "            if count_upper_nomolar_molar==0 and count_lower_nomolar_molar>0:\n",
    "                count = determine_opposite_quad(teeth=infered_boxes, tooth_register=infered_tooth_register, is_upperQ=True)\n",
    "                print(f'{pf} has {count} Upper detection using opposite quadrant tooth!')\n",
    "                \n",
    "            if count_lower_nomolar_molar==0 and count_upper_nomolar_molar>0:\n",
    "                count = determine_opposite_quad(teeth=infered_boxes, tooth_register=infered_tooth_register, is_upperQ=False)\n",
    "                print(f'{pf} has {count} Lower detection using opposite quadrant tooth!')\n",
    "                \n",
    "            \n",
    "        \n",
    "\n",
    "            ############################################################\n",
    "                \n",
    "            # write the result to label files\n",
    "            with open(os.path.join(stage3_inference_label_path, pf + '.txt'), 'w') as f2:\n",
    "                lines = []\n",
    "                for box in infered_boxes:\n",
    "                    \n",
    "                    box_dup = 'redundant_true'\n",
    "                    if not box['is_redundant']:\n",
    "                        box_dup = 'redundant_false'\n",
    "                    \n",
    "                    le = box['molar_nonmolar_code'] + ' '+ ' '.join([*[str(r) for r in box['corners'].flatten()]]) + ' ' \\\n",
    "                        + str(box['conf']) + ' ' + box_dup + ' [' + ','.join(box['tooth_number_pred']) + '] ' \\\n",
    "                        + '[' +  ','.join(box['tooth_number_pred_conf']) + ']\\n'\n",
    "                    lines.append(le)\n",
    "\n",
    "                f2.writelines(lines)\n",
    "            \n",
    "            \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f02a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# try to visualize results\n",
    "import cv2\n",
    "img_name = 'Image221.png'\n",
    "\n",
    "pf, sf = img_name.split('.')\n",
    "img = cv2.imread(os.path.join(inference_img_path, img_name))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "label_fname = pf+'.txt'\n",
    "dimg = img.copy()\n",
    "with open(os.path.join(stage3_inference_label_path, label_fname), 'r') as f:\n",
    "    rows = f.readlines()\n",
    "    for row in rows:\n",
    "        if row.strip()!='YOLO_OBB':\n",
    "            row = row.split(' ')\n",
    "            x1,y1 = float(row[1]), float(row[2])\n",
    "            x2,y2 = float(row[3]), float(row[4])\n",
    "            x3,y3 = float(row[5]), float(row[6])\n",
    "            x4,y4 = float(row[7]), float(row[8])\n",
    "            \n",
    "           \n",
    "            tooth_lbl = row[11]\n",
    "            \n",
    "            if tooth_lbl != 'UNK':\n",
    "                dimg = cv2.drawContours(dimg, [np.asarray([[x1,y1], [x2,y2], [x3,y3], [x4,y4]], dtype=int)], 0, color=(0,255,0), thickness=4)\n",
    "                dimg = cv2.putText(img=dimg, text=tooth_lbl, org=np.array([(x1+x3)/2, (y1+y3)/2], dtype=int), fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                   fontScale=2, color=(0, 200, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "            \n",
    "\n",
    "    plt.imshow(dimg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1082aa",
   "metadata": {},
   "source": [
    "### Compute the classification numbering with Stage 1 and 3 results to get Stage 4 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3512482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_inference_label_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage1_dataset_LR_classifier/test_preds'\n",
    "groundtruth_label_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/val/labelTxt_32Cls'\n",
    "stage4_inference_label_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage4/stage4outputlabels'\n",
    "\n",
    "shutil.rmtree(stage4_inference_label_path)\n",
    "\n",
    "if not os.path.exists(stage4_inference_label_path):\n",
    "    os.makedirs(stage4_inference_label_path)\n",
    "\n",
    "# This decides the left / right sides of the image from stage 1\n",
    "image_quad = {}\n",
    "for fname in os.listdir(stage1_inference_label_path):\n",
    "    path = os.path.join(stage1_inference_label_path, fname)\n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'r') as f:\n",
    "            line = f.readline().strip()\n",
    "            imgname, _ = fname.split('.')\n",
    "            image_quad[imgname] = line\n",
    "            \n",
    "\n",
    "teeth_map ={ 'RIGHT': {'U3':'t13' , 'U4':'t14', 'U5':'t15', 'U6':'t16', 'U7':'t17', 'U8':'t18',\n",
    "                       'L3':'t43' , 'L4':'t44', 'L5':'t45', 'L6':'t46', 'L7':'t47', 'L8':'t48'},\n",
    "           \n",
    "             'LEFT': {'U3':'t23' , 'U4':'t24', 'U5':'t25', 'U6':'t26', 'U7':'t27', 'U8':'t28',\n",
    "                      'L3':'t33' , 'L4':'t34', 'L5':'t35', 'L6':'t36', 'L7':'t37', 'L8':'t38'}\n",
    "              } \n",
    "\n",
    "\n",
    "teeth_predictions = {}\n",
    "for fname in os.listdir(groundtruth_label_path):\n",
    "    path = os.path.join(groundtruth_label_path, fname)\n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'r') as f:\n",
    "            imgname, _ = fname.split('.')\n",
    "            teeth_predictions[imgname] = {}\n",
    "            teeth_predictions[imgname]['ground_truth'] = {}\n",
    "            \n",
    "            for k, row in enumerate(f.readlines()):\n",
    "                row = row.split()\n",
    "                rect_coor = np.array( [ [float(row[0]), float(row[1])],\n",
    "                                        [float(row[2]), float(row[3])],\n",
    "                                        [float(row[4]), float(row[5])],\n",
    "                                        [float(row[6]), float(row[7])] ] )\n",
    "                tooth_label = row[8]\n",
    "                line = [tooth_label, rect_coor]\n",
    "                teeth_predictions[imgname]['ground_truth'][k] = line\n",
    "\n",
    "\n",
    "for fname in os.listdir(stage3_inference_label_path):\n",
    "    path = os.path.join(stage3_inference_label_path, fname)\n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'r') as f:\n",
    "            imgname, _ = fname.split('.')\n",
    "            teeth_predictions[imgname]['prediction'] = {}\n",
    "            \n",
    "            for k, row in enumerate(f.readlines()):\n",
    "                row = row.split()\n",
    "                \n",
    "                lbs = row[-2].strip('[]').split(',')\n",
    "                confs = [float(x) for x in row[-1].strip('[]').split(',') if len(x)>0]\n",
    "                lb = lbs[np.argmax(confs)] if len(confs)>0 else None\n",
    "\n",
    "                \n",
    "                tooth_label = teeth_map[image_quad[imgname]].get(lb, 'unknown')\n",
    "                \n",
    "                rect_coor = np.array( [ [float(row[1]), float(row[2])],\n",
    "                                        [float(row[3]), float(row[4])],\n",
    "                                        [float(row[5]), float(row[6])],\n",
    "                                        [float(row[7]), float(row[8])] ] )\n",
    "                \n",
    "                conf = float(row[9])\n",
    "                line = [tooth_label, rect_coor, conf]\n",
    "                teeth_predictions[imgname]['prediction'][k] = line\n",
    "                #print(f'{fname} {line}')\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(r1, r2):\n",
    "    r1 = Polygon(r1)\n",
    "    r2 = Polygon(r2)\n",
    "\n",
    "    iou = r1.intersection(r2).area / r1.union(r2).area\n",
    "    return iou\n",
    "            \n",
    "    \n",
    "# Export the combined prediction results\n",
    "def ExportInferenceFiles(export_path, img_names, pred_labels, pred_rects, pred_conf):\n",
    " \n",
    "    if not os.path.exists(export_path):\n",
    "        os.makedirs(export_path)\n",
    "    else:\n",
    "        shutil.rmtree(export_path)\n",
    "        os.makedirs(export_path)\n",
    "        \n",
    "        \n",
    "    for fname, lbl, rect, conf in zip(img_names, pred_labels, pred_rects, pred_conf):\n",
    "        path = os.path.join(export_path, fname + '.txt')\n",
    "        with open(path, 'a') as f:\n",
    "            if lbl != 'unknown':\n",
    "                rect = [str(r) for r in rect.flatten()]\n",
    "                line = ' '.join([lbl, *rect, str(conf)]) + '\\n'\n",
    "                f.writelines(line)\n",
    "\n",
    "\n",
    "img_names = []\n",
    "groud_truth_labels = []\n",
    "pred_labels = []\n",
    "pred_conf = []\n",
    "box_ious = []\n",
    "pred_rects = []\n",
    "\n",
    "for img, val in teeth_predictions.items():\n",
    "    \n",
    "    gt_rects = [ x[1] for x in val['ground_truth'].values()]\n",
    "        \n",
    "    for gt_lbl, gt_rect in val['ground_truth'].values():\n",
    "        \n",
    "        matched_iou = 0\n",
    "        matched_pd_lbl = 'unknown'\n",
    "        matched_pd_rect = []\n",
    "        matched_pd_conf = 0\n",
    "        \n",
    "        #Get the most overlapped predicted box with the gt box\n",
    "        if val.get('prediction', None) is not None:\n",
    "        \n",
    "            for pd_lbl, pd_rect, pd_conf in val['prediction'].values():\n",
    "                iou = calculate_iou(gt_rect, pd_rect)\n",
    "                if iou>0.5:\n",
    "                    matched_pd_lbl = pd_lbl if iou > matched_iou else matched_pd_lbl\n",
    "                    matched_pd_rect = pd_rect if iou > matched_iou else matched_pd_rect\n",
    "                    matched_pd_conf = pd_conf if iou > matched_iou else matched_pd_conf\n",
    "                    matched_iou = iou if iou > matched_iou else matched_iou\n",
    "\n",
    "        if gt_lbl not in ['t11', 't12', 't21', 't22', 't31', 't32', 't41', 't42']:\n",
    "            img_names.append(img)\n",
    "            groud_truth_labels.append(gt_lbl)\n",
    "            pred_labels.append(matched_pd_lbl)\n",
    "            box_ious.append(matched_iou)\n",
    "            pred_conf.append(matched_pd_conf)\n",
    "            pred_rects.append(matched_pd_rect)\n",
    "\n",
    " \n",
    "# Export the combined prediction results\n",
    "ExportInferenceFiles(stage4_inference_label_path,  img_names, pred_labels, pred_rects, pred_conf)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b37ede5",
   "metadata": {},
   "source": [
    "### Examine and compute the performance metrics\n",
    "\n",
    "In YoLo, the confidence score is confidence whether the bounding box has the object of that class.\n",
    "Each grid cell also predicts C conditional class probabilities Pr(Classi|Object). It only predicts one set of class probabilities per grid cell, regardless of the number of boxes B. During testing, these conditional class probabilities are multiplied by individual box confidence predictions which give class-specific confidence scores for each box. These scores show both the probability of that class and how well the box fits the object.\n",
    "https://towardsdatascience.com/object-detection-part1-4dbe5147ad0a\n",
    "\n",
    "Pr(Class i|Object)*Pr(Object)*IoU = Pr(Class i)*IoU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize = (8,5))\n",
    "\n",
    "ax[0].hist(box_ious, bins=100)\n",
    "ax[1].hist(pred_conf, bins=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bda30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average IoU at IoU_Threshold=0 : {round(sum(box_ious)/len(box_ious),3)}' )\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c17188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def CustomizeClassificationReport(gt_lbls, pred_lbls):\n",
    "\n",
    "    cr_dict = classification_report(gt_lbls, pred_lbls, zero_division=0, output_dict=True)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    for cr_class, cr_val in cr_dict.items():\n",
    "        if cr_class in set(groud_truth_labels):\n",
    "            precisions.append(cr_val['precision'])\n",
    "            recalls.append(cr_val['recall'])\n",
    "            f1_scores.append(cr_val['f1-score'])\n",
    "            line = cr_class + ',' + str(round(cr_val['precision'],3)) + ',' + str(round(cr_val['recall'],3)) + ',' + str(round(cr_val['f1-score'],3))\n",
    "            print(line)\n",
    "\n",
    "    line = 'Macro Avg,' + str(round(np.mean(precisions),3)) + ',' + str(round(np.mean(recalls),3)) + ',' + str(round(np.mean(f1_scores),3))\n",
    "    print(line)\n",
    "    \n",
    "print(f\"Classification report at IoU_Threshold=0:\\n \")\n",
    "CustomizeClassificationReport(groud_truth_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52306fc",
   "metadata": {},
   "source": [
    "### Examine the case when directly using YOLO to train 32 classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cebdc3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "valid_32cls_lbls = ['t11','t12','t13','t14','t15','t16','t17','t18',\n",
    "                  't21','t22','t23','t24','t25','t26','t27','t28',\n",
    "                  't31','t32','t33','t34','t35','t36','t37','t38',\n",
    "                  't41','t42','t43','t44','t45','t46','t47','t48']\n",
    "\n",
    "valid_16cls_lbls = ['U1','U2','U3','U4','U5','U6','U7','U8',\n",
    "                  'L1','L2','L3','L4','L5','L6','L7','L8']\n",
    "\n",
    "\n",
    "teeth_map ={ 'RIGHT': {'U1':'t11' , 'U2':'t12', 'U3':'t13' , 'U4':'t14', 'U5':'t15', 'U6':'t16', 'U7':'t17', 'U8':'t18',\n",
    "                       'L1':'t41' , 'L2':'t42', 'L3':'t43' , 'L4':'t44', 'L5':'t45', 'L6':'t46', 'L7':'t47', 'L8':'t48'},\n",
    "           \n",
    "             'LEFT': {'U1':'t21' , 'U2':'t22', 'U3':'t23' , 'U4':'t24', 'U5':'t25', 'U6':'t26', 'U7':'t27', 'U8':'t28',\n",
    "                      'L1':'t31' , 'L2':'t32', 'L3':'t33' , 'L4':'t34', 'L5':'t35', 'L6':'t36', 'L7':'t37', 'L8':'t38'}\n",
    "              } \n",
    "\n",
    "\n",
    "def ComputeDetection(yolo_label_path, no_classes, inf_label_path):\n",
    "    \n",
    "    if no_classes != 16 and no_classes !=32:\n",
    "        print(f'Invalid no_classes: {no_classes}')\n",
    "        return\n",
    "        \n",
    "    teeth_predictions_yolo_direct = {}\n",
    "    for fname in os.listdir(groundtruth_label_path):\n",
    "        path = os.path.join(groundtruth_label_path, fname)\n",
    "        if os.path.isfile(path):\n",
    "            with open(path, 'r') as f:\n",
    "                imgname, _ = fname.split('.')\n",
    "                teeth_predictions_yolo_direct[imgname] = {}\n",
    "                teeth_predictions_yolo_direct[imgname]['ground_truth'] = {}\n",
    "\n",
    "                for k, row in enumerate(f.readlines()):\n",
    "                    row = row.split()\n",
    "                    rect_coor = np.array( [ [float(row[0]), float(row[1])],\n",
    "                                            [float(row[2]), float(row[3])],\n",
    "                                            [float(row[4]), float(row[5])],\n",
    "                                            [float(row[6]), float(row[7])] ] )\n",
    "                    tooth_label = row[8]\n",
    "                    line = [tooth_label, rect_coor]\n",
    "                    teeth_predictions_yolo_direct[imgname]['ground_truth'][k] = line\n",
    "\n",
    "\n",
    "    for fname in os.listdir(yolo_label_path):\n",
    "        path = os.path.join(yolo_label_path, fname)\n",
    "        if os.path.isfile(path):\n",
    "            with open(path, 'r') as f:\n",
    "                imgname, _ = fname.split('.')\n",
    "                teeth_predictions_yolo_direct[imgname]['prediction'] = {}\n",
    "\n",
    "                for k, row in enumerate(f.readlines()):\n",
    "                    row = row.split()\n",
    "                    \n",
    "                    if no_classes==32:\n",
    "                        tooth_label = valid_32cls_lbls[int(row[0])]\n",
    "                    elif no_classes==16:\n",
    "                        tooth_label = valid_16cls_lbls[int(row[0])]\n",
    "\n",
    "                    rect_coor = np.array( [ [float(row[1]), float(row[2])],\n",
    "                                            [float(row[3]), float(row[4])],\n",
    "                                            [float(row[5]), float(row[6])],\n",
    "                                            [float(row[7]), float(row[8])] ] )\n",
    "\n",
    "                    conf = float(row[9])\n",
    "                    line = [tooth_label, rect_coor, conf]\n",
    "                    teeth_predictions_yolo_direct[imgname]['prediction'][k] = line\n",
    "                    #print(f'{fname} {line}')\n",
    "\n",
    "\n",
    "    img_names = []\n",
    "    groud_truth_labels = []\n",
    "    pred_labels = []\n",
    "    pred_conf = []\n",
    "    box_ious = []\n",
    "    pred_rects = []\n",
    "    \n",
    "    for img, val in teeth_predictions_yolo_direct.items():\n",
    "\n",
    "        for gt_lbl, gt_rect in val['ground_truth'].values():\n",
    "\n",
    "            matched_iou = 0\n",
    "            matched_pd_lbl = 'unknown'\n",
    "            matched_pd_rect = []\n",
    "            matched_pd_conf = 0\n",
    "\n",
    "            #Get the overlapped predicted box>0.5 with the gt box, and the one with highest conf\n",
    "            if val.get('prediction', None) is not None:\n",
    "\n",
    "                max_conf = 0\n",
    "                for pd_lbl, pd_rect, pd_conf in val['prediction'].values():\n",
    "\n",
    "                    iou = calculate_iou(gt_rect, pd_rect)                \n",
    "                    if iou>0.5:\n",
    "                        if no_classes==16:\n",
    "                            #################\n",
    "                            # Correction by using Stage 1 results\n",
    "                            pd_lbl = teeth_map[image_quad[img]][pd_lbl]\n",
    "                            \n",
    "                            matched_pd_lbl = pd_lbl if max_conf<pd_conf else matched_pd_lbl\n",
    "                            matched_pd_rect = pd_rect if max_conf<pd_conf else matched_pd_rect\n",
    "                            matched_pd_conf = pd_conf if max_conf<pd_conf else matched_pd_conf\n",
    "\n",
    "                            matched_iou = iou if max_conf<pd_conf else matched_iou\n",
    "                            max_conf = pd_conf if max_conf<pd_conf else max_conf\n",
    "                            ###################\n",
    "                        \n",
    "                        if no_classes==32:\n",
    "                            #################\n",
    "                            # only those predicted box with iou > 0.5 is going to be considered. Take those with highest confidence as prediction \n",
    "                            matched_pd_lbl = pd_lbl if max_conf<pd_conf else matched_pd_lbl\n",
    "                            matched_pd_rect = pd_rect if max_conf<pd_conf else matched_pd_rect\n",
    "                            matched_pd_conf = pd_conf if max_conf<pd_conf else matched_pd_conf\n",
    "                            matched_iou = iou if max_conf<pd_conf else matched_iou\n",
    "                            max_conf = pd_conf if max_conf<pd_conf else max_conf\n",
    "                            \n",
    "                            ###################\n",
    "                                \n",
    "\n",
    "            if gt_lbl not in ['t11', 't12', 't21', 't22', 't31', 't32', 't41', 't42']:\n",
    "                img_names.append(img)\n",
    "                groud_truth_labels.append(gt_lbl)\n",
    "                pred_labels.append(matched_pd_lbl)\n",
    "                box_ious.append(matched_iou)\n",
    "                pred_conf.append(matched_pd_conf)\n",
    "                pred_rects.append(matched_pd_rect)\n",
    "\n",
    "\n",
    "    print(f'Average IoU at IoU_Threshold=0 : {round(sum(box_ious)/len(box_ious),3)}' )\n",
    "\n",
    "    print(f\"Classification report at IoU_Threshold=0:\")\n",
    "    CustomizeClassificationReport(groud_truth_labels, pred_labels)\n",
    "    \n",
    "    ExportInferenceFiles(inf_label_path,  img_names, pred_labels, pred_rects, pred_conf)\n",
    "    \n",
    "    \n",
    "yolo5n_32cls_inf_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/6XX_32cls_scratch_yolo5n_detect_conf0p6_iou0p45_/labels'\n",
    "yolo5n_16cls_inf_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/6XX_16cls_scratch_yolo5n_detect_conf0p6_iou0p45_/labels'\n",
    "    \n",
    "yolo5m_32cls_inf_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/6XX_32cls_scratch_yolo5m_detect_conf0p6_iou0p45_/labels'\n",
    "yolo5m_16cls_inf_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/6XX_16cls_scratch_yolo5m_detect_conf0p6_iou0p45_/labels'\n",
    "\n",
    "yolo5x_32cls_inf_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/6XX_32cls_scratch_yolo5x_detect_conf0p6_iou0p45_/labels'\n",
    "yolo5x_16cls_inf_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage2_yolo_obb/6XX_16cls_scratch_yolo5x_detect_conf0p6_iou0p45_/labels'\n",
    "\n",
    "\n",
    "yolo5m_32cls_output_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage4/stage4outputlabels_yolo5m_32cls'\n",
    "yolo5m_16cls_output_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage4/stage4outputlabels_yolo5m_16cls'\n",
    "\n",
    "\n",
    "\n",
    "ComputeDetection(yolo5m_32cls_inf_path, 32, yolo5m_32cls_output_path)\n",
    "\n",
    "ComputeDetection(yolo5m_16cls_inf_path, 16, yolo5m_16cls_output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5789abbf",
   "metadata": {},
   "source": [
    "### Generate predicted images for evaluation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd0ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad367b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "stage4_inference_img_path = './4 Private ZOON Anonymised/Bitewing_proc/labels_trial6XX/Stage4/stage4predictedimages'\n",
    "\n",
    "\n",
    "if not os.path.exists(stage4_inference_img_path):\n",
    "    os.makedirs(stage4_inference_img_path)\n",
    "else:\n",
    "    shutil.rmtree(stage4_inference_img_path)\n",
    "    os.makedirs(stage4_inference_img_path)\n",
    "    \n",
    "\n",
    "def sort_coordinates(list_of_xy_coords, is_clockwise):\n",
    "    cx, cy = list_of_xy_coords.mean(0)\n",
    "    x, y = list_of_xy_coords.T\n",
    "    angles = np.arctan2(x-cx, y-cy)\n",
    "    indices = np.argsort(-1*angles) if is_clockwise else np.argsort(angles)\n",
    "    \n",
    "    return list_of_xy_coords[indices]\n",
    "\n",
    "def OutputPredImages(inf_lbl_path, ind_lbl, ind_coors, img_suffix, lbl_map, annotation_color):\n",
    "    for fname in os.listdir(inf_lbl_path):\n",
    "        path = os.path.join(inf_lbl_path, fname)\n",
    "        imgname, _ = fname.split('.')\n",
    "        imgname = imgname + '.png'\n",
    "\n",
    "        img = cv2.imread(os.path.join(val_img_path, imgname))\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if os.path.isfile(path):\n",
    "            with open(path, 'r') as f:\n",
    "                rows = f.readlines()\n",
    "                for row in rows:\n",
    "                    if row.strip()!='YOLO_OBB':\n",
    "                        row = row.split(' ')\n",
    "                        x1,y1 = float(row[ind_coors[0]]), float(row[ind_coors[1]])\n",
    "                        x2,y2 = float(row[ind_coors[2]]), float(row[ind_coors[3]])\n",
    "                        x3,y3 = float(row[ind_coors[4]]), float(row[ind_coors[5]])\n",
    "                        x4,y4 = float(row[ind_coors[6]]), float(row[ind_coors[7]])\n",
    "                        \n",
    "                        coors = np.asarray([[x1,y1], [x2,y2], [x3,y3], [x4,y4]], dtype=int)\n",
    "                        coors = sort_coordinates(coors, True)\n",
    "                        \n",
    "                        if lbl_map is None:\n",
    "                            tooth_lbl = row[ind_lbl]\n",
    "                        else:\n",
    "                            tooth_lbl = lbl_map[int(row[ind_lbl])]\n",
    "                        \n",
    "                        diag = np.linalg.norm(np.array([x1,y1])-np.array([x3,y3]))\n",
    "                        \n",
    "                        text_coor = np.array(0.5*(coors[0] + coors[2]) , dtype=int)\n",
    "                      \n",
    "                    \n",
    "                        img = cv2.drawContours(img, [coors], 0, color=annotation_color, thickness=4)\n",
    "                        img = cv2.putText(img=img, text=tooth_lbl, org=text_coor, fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                           fontScale=2, color=annotation_color, thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "                imgname, _ = fname.split('.')\n",
    "                imgname = imgname + '_' + img_suffix + '.png'\n",
    "                cv2.imwrite(os.path.join(stage4_inference_img_path, imgname), img)\n",
    "    \n",
    "    \n",
    "# Output the Ground Truth prediction\n",
    "OutputPredImages(val_label_32cls_path, 8, range(0,8), 'gt', None, (255, 0, 100))\n",
    "    \n",
    "# Output the Stage 4 prediction\n",
    "OutputPredImages(stage4_inference_label_path, 0, range(1,9), 'pred', None, (0, 0, 250))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93047883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the 32cls detection images\n",
    "OutputPredImages(yolo5m_32cls_output_path, 0, range(1,9), '32cls_direct', None, (50, 250, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5087a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "OutputPredImages(yolo5m_16cls_output_path, 0, range(1,9), '16cls_direct', None, (14, 253, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cca570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd114851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
